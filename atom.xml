<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Obito Blog</title>
  
  <subtitle>Weclome to my blog</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-08-07T12:34:42.218Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Obito</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>华为开发者大会2023</title>
    <link href="http://example.com/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/"/>
    <id>http://example.com/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/</id>
    <published>2023-08-06T10:02:16.000Z</published>
    <updated>2023-08-07T12:34:42.218Z</updated>
    
    <content type="html"><![CDATA[<h2 id="华为开发者大会2023"><a href="#华为开发者大会2023" class="headerlink" title="华为开发者大会2023"></a>华为开发者大会2023</h2><p>得益于郑老师和华为终端公司有一个产学合作协同育人项目，对方提供了一次 8 月 6 日参加 HDC华为开发者大会的机会，因此我们能够参加此次开发者大会。</p><p>每个进场的人都有分配一个牌子，上面有个人的信息，二维码也是用来识别身份的。这个牌子真的很好看！特别是在太阳光的照射下，可以更明显得看出不同颜色。</p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3352.png"></p><p>大会分三天，每天都有不同的安排，最后一天也就是 6 号主要是 HarmonyOS学生公开课。</p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3376.jpg"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3374.jpg"></p><p>今天也是十分幸运，在公开课上答题获奖了，然后扫描二维码抽到了开发板（只有10个名额）！！，这个开发板是可以用来开发鸿蒙系统的，很是期待！！</p><p>书包是去年的，里面有一件白T但没logo，今年的T恤有logo；一个红色水杯，一个胸针。</p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3389.jpg"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3393.webp"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3396.jpg"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3397.jpg"></p><p>打卡一些活动获取活力值兑换的奖品，一开始以为挂包是大的那种，早知道就换个书包了！！</p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3398.jpg"></p><p>光顾着玩了没怎么拍照片！</p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3354.jpg"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3353.jpg"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3387.png"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3369.jpg"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3353.jpg"></p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3384.jpg"></p><p>没有退路就是胜利之路！</p><p>期待下一次的到来(如果有机会的话hhh)。</p><p><img src="/2023/08/06/%E5%8D%8E%E4%B8%BA%E5%BC%80%E5%8F%91%E8%80%85%E5%A4%A7%E4%BC%9A2023/IMG_3383.jpg" alt="IMG_3393"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;华为开发者大会2023&quot;&gt;&lt;a href=&quot;#华为开发者大会2023&quot; class=&quot;headerlink&quot; title=&quot;华为开发者大会2023&quot;&gt;&lt;/a&gt;华为开发者大会2023&lt;/h2&gt;&lt;p&gt;得益于郑老师和华为终端公司有一个产学合作协同育人项目，对方提供了一次</summary>
      
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>基于opencv的车道线检测</title>
    <link href="http://example.com/2023/08/01/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/"/>
    <id>http://example.com/2023/08/01/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/</id>
    <published>2023-08-01T10:16:53.000Z</published>
    <updated>2023-08-07T10:01:19.125Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于Opencv的车道线检测"><a href="#基于Opencv的车道线检测" class="headerlink" title="基于Opencv的车道线检测"></a>基于Opencv的车道线检测</h1><h2 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h2><p>这只是一个简单的检测，并不具有普遍性。车道线检测的应用很广泛，小到一些智能小车的巡线功能，大到无人驾驶巡线功能等，一般用于小车运动应用，但是在不同场景下，它们的需求大不相同，因此也就需要不同的技术去实现。本次实验采用opencv来实现，主要是用来复习巩固自己所学知识，同时由于是基于opencv实现的传统方法，没有运用一些模型来训练等，因此项目并不具有普遍性，需要根据不同视频进行调参。</p><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p>Window 10、Visual Studio 2022、 opencv4.6</p><h2 id="涉及到的一些知识"><a href="#涉及到的一些知识" class="headerlink" title="涉及到的一些知识"></a>涉及到的一些知识</h2><h3 id="霍夫变换"><a href="#霍夫变换" class="headerlink" title="霍夫变换"></a>霍夫变换</h3><p>霍夫变换(Hough Transform)是图像处理中的一种特征提取技术，该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。</p><h3 id="Opencv中的霍夫线变换"><a href="#Opencv中的霍夫线变换" class="headerlink" title="Opencv中的霍夫线变换"></a>Opencv中的霍夫线变换</h3><p>霍夫线变换是一种用来寻找直线的方法。在使用霍夫线变换之前，首先要对图像进行边缘检测的处理，因此霍夫线变换的<strong>输入必须是二值图像</strong>。</p><p>OpenCV支持三种不同的霍夫线变换</p><ul><li>标准霍夫变换(Standard Hough Transform，SHT)</li><li>多尺度霍夫变换（Multi-Scale Hough Transform，MSHT）</li><li>累计概率霍夫变换(Progressive Probabilistic Hough Transform ，PPHT)</li></ul><p>其中，多尺度霍夫变换（MSHT）为经典霍夫变换（SHT）在多尺度下的一个变种。累计概率霍夫变换(PPHT）算法是标准霍夫变换（SHT）算法的一个改进，它在一定的范围内进行霍夫变换，计算单独线段的方向以及范围，从而减少计算量，缩短计算时间。之所以称PPHT为“概率”的，是因为并不将累加器平面内的所有可能的点累加，而<strong>只是累加其中的一部分</strong>，该想法是如果峰值如果足够高，只用一小部分时间去寻找它就够了，可以实质性地减少计算时间。</p><p>在OpenCV中，我们可以用HoughLines函数来调用标准霍夫变换SHT和多尺度霍夫变换MSHT。</p><p>而HoughLinesP函数用于调用累计概率霍夫变换PPHT。累计概率霍夫变换执行效率很高，所有相比于HoughLines函数，<strong>我们更倾向于使用HoughLinesP函数。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CV_EXPORTS_W <span class="type">void</span> <span class="title">HoughLinesP</span><span class="params">( InputArray image, OutputArray lines,</span></span></span><br><span class="line"><span class="params"><span class="function">                               <span class="type">double</span> rho, <span class="type">double</span> theta, <span class="type">int</span> threshold,</span></span></span><br><span class="line"><span class="params"><span class="function">                               <span class="type">double</span> minLineLength = <span class="number">0</span>, <span class="type">double</span> maxLineGap = <span class="number">0</span> )</span></span>;</span><br><span class="line"><span class="comment">//InputArray image：输入图像，必须是8位单通道图像。 </span></span><br><span class="line"><span class="comment">//OutputArray lines：输出检测到的线条参数集合。 </span></span><br><span class="line"><span class="comment">//double rho：直线搜索时的距离r步长，以像素为单位，一般为1。 </span></span><br><span class="line"><span class="comment">//double theta：直线搜索时的角度θ步长，以弧度为单位，一般为CV_PI/180。 </span></span><br><span class="line"><span class="comment">//int threshold：累加计数值的阈值参数，当参数空间某个交点的累加计数的值超过该阈值，则认为该交点对应了图像空间的一条直线。 </span></span><br><span class="line"><span class="comment">//double minLineLength：默认值为0，表示最小线段长度阈值（像素），超过该阈值才有机会认定为直线。 </span></span><br><span class="line"><span class="comment">//double maxLineGap：线段上最近两点之间的阈值.默认值为0，表示直线断裂的最大间隔距离阈值。即如果有两条线段是在一条直线上，但它们之间有间隙，那么如果这个间隔距离小于该值，则被认为是一条线段，否则认为是两条线段。 </span></span><br><span class="line"></span><br><span class="line">r和θ步长越小，搜索时间越长。</span><br><span class="line">lines 参数为直线起点和终点 x1,y1,x2,y2 因此一般定义为vector&lt;Vec4i&gt; lines;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CV_EXPORTS_W <span class="type">void</span> <span class="title">HoughLines</span><span class="params">( InputArray image, OutputArray lines, </span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">double</span> rho, <span class="type">double</span> theta, <span class="type">int</span> threshold, </span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">double</span> srn = <span class="number">0</span>, <span class="type">double</span> stn = <span class="number">0</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">double</span> min_theta = <span class="number">0</span>, <span class="type">double</span> max_theta = CV_PI )</span></span>;</span><br><span class="line">　　</span><br><span class="line"><span class="comment">//InputArray image：输入图像，必须是8位单通道图像。 </span></span><br><span class="line"><span class="comment">//OutputArray lines：检测到的线条参数集合。 </span></span><br><span class="line"><span class="comment">//double rho：以像素为单位的距离r步长，一般为1。。 </span></span><br><span class="line"><span class="comment">//double theta：以弧度为单位的角度θ步长，一般为CV_PI/180。 </span></span><br><span class="line"><span class="comment">//int threshold：累加计数值的阈值参数，当参数空间某个交点的累加计数的值超过该阈值，则认为该交点对应了图像空间的一条直线。 </span></span><br><span class="line"><span class="comment">//double srn：默认值为0，用于在多尺度霍夫变换中作为参数rho的除数，rho=rho/srn。 </span></span><br><span class="line"><span class="comment">//double stn：默认值为0，用于在多尺度霍夫变换中作为参数theta的除数，theta=theta/stn。</span></span><br><span class="line"><span class="comment">//如果srn和stn同时为0，就表示HoughLines函数执行标准霍夫变换，否则就是执行多尺度霍夫变换。</span></span><br><span class="line"></span><br><span class="line">lines 参数为r，θ，一般定义为 vector&lt;Vec2f&gt; lines;</span><br></pre></td></tr></table></figure><h3 id="霍夫线变换部分原理"><a href="#霍夫线变换部分原理" class="headerlink" title="霍夫线变换部分原理"></a>霍夫线变换部分原理</h3><p><strong>极坐标方式作为参数空间。图像坐标系到极坐标系参数空间的转换过程</strong>：</p><p><img src="/2023/08/01/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/md35.png" alt="md35"></p><p>从上面可以看到，<strong>参数空间的每个点(ρ,θ)都对应了图像空间的一条直线</strong>，换个角度说就是<strong>图像空间的一个点在参数空间中就对应为一条曲线。</strong>参数空间采用极坐标系，这样就可以在参数空间表示原始空间中的所有直线了。</p><p><strong>极坐标系参数空间到图像坐标系的转换过程：</strong></p><p><img src="/2023/08/01/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/md36.png" alt="md36"></p><p><img src="/2023/08/01/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/md37.png" alt="md37"></p><p>这样就把在图像空间中检测直线的问题转化为在极坐标参数空间中找通过点(r,θ)的最多正弦曲线数的问题。霍夫空间中，曲线的交点次数越多，所代表的参数越确定，画出的图形越饱满。</p><p>实际上，图像空间的一个点并不能确认一条直线，可以对应无数条直线，因此在实际应用中，我们必须用各种条件限定直线的数量。</p><p>我们将直线的方向θ离散化为有限个等间距的离散值，参数ρ也就对应离散化为有限个值，于是参数空间不再是连续的，而是被离散量化为一个个等大小网格单元。将图像空间（直角坐标系）中每个像素点坐标值变换到参数空间（极坐标系）后，所得值会落在某个网格内，使该网格单元的累加计数器加1。当图像空间中所有的像素都经过霍夫变换后，对网格单元进行检查，累加计数值最大的网格，其坐标值（$ρ_0$, $θ_0$）就对应图像空间中所求的直线。</p><p><strong>离散化过程：</strong></p><p><img src="/md38.png" alt="md38"></p><p><strong>霍夫直线检测的优缺点</strong></p><ul><li><p>优点：Hough直线检测的优点是<strong>抗干扰能力强</strong>，对图像中直线的残缺部分、噪声以及其它共存的非直线结构不敏感，能容忍特征边界描述中的间隙，并且<strong>相对不受图像噪声</strong>的影响</p></li><li><p>缺点：Hough变换算法的特点导致其<strong>时间复杂度和空间复杂度都很高</strong>，并且在检测过程中只能确定直线方向，<strong>丢失了线段的长度信息</strong>。由于霍夫检测过程中进行了离散化，因此检测精度受参数离散间隔制约</p></li></ul><h3 id="直线拟合函数-fitLine"><a href="#直线拟合函数-fitLine" class="headerlink" title="直线拟合函数 fitLine()"></a>直线拟合函数 fitLine()</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CV_EXPORTS_W <span class="type">void</span> <span class="title">fitLine</span><span class="params">( InputArray points, OutputArray line, <span class="type">int</span> distType,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">double</span> param, <span class="type">double</span> reps, <span class="type">double</span> aeps )</span></span>;</span><br><span class="line"><span class="comment">//InputArray points, 输入需要拟合的直线点集，一般为vector&lt;Point&gt; left_point。</span></span><br><span class="line"><span class="comment">//OutputArray line, 输出的直线向量，一般为Vec4f left_line</span></span><br><span class="line"><span class="comment">//int distType,拟合直线采用的方法</span></span><br><span class="line"><span class="comment">//double param,距离参数，一般为。</span></span><br><span class="line"><span class="comment">//double reps, 径向的精度，通常为1e-2即0.01。</span></span><br><span class="line"><span class="comment">//double aeps角度的精度，通常为1e-2即0.01。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">line 的形式为 cos sin x y 夹角和一个坐标点</span><br></pre></td></tr></table></figure><p><strong>distType的类型:</strong><img src="/2023/08/01/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/md39.png" alt="md39"></p><h3 id="RotatedRect类"><a href="#RotatedRect类" class="headerlink" title="RotatedRect类"></a>RotatedRect类</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CV_EXPORTS</span> RotatedRect</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">RotatedRect</span>();</span><br><span class="line">    <span class="comment">/** full constructor</span></span><br><span class="line"><span class="comment">    @param center The rectangle mass center.</span></span><br><span class="line"><span class="comment">    @param size Width and height of the rectangle.</span></span><br><span class="line"><span class="comment">    @param angle The rotation angle in a clockwise direction. When the angle is 0, 90, 180, 270 etc.,</span></span><br><span class="line"><span class="comment">    the rectangle becomes an up-right rectangle.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="built_in">RotatedRect</span>(<span class="type">const</span> Point2f&amp; center, <span class="type">const</span> Size2f&amp; size, <span class="type">float</span> angle);</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    Any 3 end points of the RotatedRect. They must be given in order (either clockwise or anticlockwise).</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="built_in">RotatedRect</span>(<span class="type">const</span> Point2f&amp; point1, <span class="type">const</span> Point2f&amp; point2, <span class="type">const</span> Point2f&amp; point3);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** returns 4 vertices of the rectangle</span></span><br><span class="line"><span class="comment">    @param pts The points array for storing rectangle vertices. The order is bottomLeft, topLeft, topRight, bottomRight.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">points</span><span class="params">(Point2f pts[])</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="comment">//! returns the minimal up-right integer rectangle containing the rotated rectangle</span></span><br><span class="line">    <span class="function">Rect <span class="title">boundingRect</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="comment">//! returns the minimal (exact) floating point rectangle containing the rotated rectangle, not intended for use with images</span></span><br><span class="line">    <span class="function">Rect_&lt;<span class="type">float</span>&gt; <span class="title">boundingRect2f</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="comment">//! returns the rectangle mass center</span></span><br><span class="line">    Point2f center;</span><br><span class="line">    <span class="comment">//! returns width and height of the rectangle</span></span><br><span class="line">    Size2f size;</span><br><span class="line">    <span class="comment">//! returns the rotation angle. When the angle is 0, 90, 180, 270 etc., the rectangle becomes an up-right rectangle.</span></span><br><span class="line">    <span class="type">float</span> angle;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">该类有中心点center、尺寸<span class="built_in">size</span>(width, height)、旋转角度angle三个成员</span><br></pre></td></tr></table></figure><p>该类中的旋转角度暂时没搞懂怎么看的，查了许多资料都挺乱的，待定。</p><blockquote><p><a href="https://blog.csdn.net/sandalphon4869/article/details/102258634">OpenCV之RotatedRect基本用法和角度探究_opencv rotatedrect_sandalphon4869的博客-CSDN博客</a></p><p><a href="https://stackoverflow.com/questions/15956124/minarearect-angles-unsure-about-the-angle-returned/21427814#21427814">https://stackoverflow.com/questions/15956124/minarearect-angles-unsure-about-the-angle-returned/21427814#21427814</a></p><p><a href="https://stackoverflow.com/questions/24073127/opencvs-rotatedrect-angle-does-not-provide-enough-information">https://stackoverflow.com/questions/24073127/opencvs-rotatedrect-angle-does-not-provide-enough-information</a></p></blockquote><h2 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h2><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><ol><li>预处理图像<ol><li>读取视频帧。对视频的每一帧图像进行处理。</li><li>去噪声。高斯滤波器。</li><li>灰度化处理。颜色信息对车道线检测关系不大。</li><li>二值化处理。便于后续提取车道线</li></ol></li><li>提取ROI区域<ol><li>提取车道线。通过画图工具找坐标，调整参数将车道ROI区域截取处理。、</li><li>轮廓处理。对ROI区域进行轮廓处理</li></ol></li><li>绘制车道线<ol><li>优化轮廓。对提取出来的轮廓内的坐标进行处理，一般只提取最大值和最小值。</li><li>绘制直线。根据优化后的坐标进行绘制车道线。</li></ol></li></ol><p>这种方法在绘制车道线时，主要是通过寻找轮廓函数findContours里面的返回值，对返回值进行提取角度、坐标最小值和最大值，从而进行优化并绘制直线。</p><h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><ol><li>预处理图像<ol><li>读取视频帧。对视频的每一帧图像进行处理。</li><li>灰度化处理。颜色信息对车道线检测关系不大。</li><li>边缘检测。Canny检测，由于内部已经有进行高斯滤波处理，因此不用再单独进行滤波处理了。</li></ol></li><li>提取ROI区域<ol><li>提取车道线。通过画图工具找坐标，调整参数将车道ROI区域截取处理。</li></ol></li><li>对车道线处理<ol><li>霍夫直接检测。取出所有直线。</li><li>优化处理直线。根据直线斜率判断、根据分布分为左右边车道线、最小二乘法拟合直线。</li></ol></li><li>绘制车道线<ol><li>根据优化后的直线参数，计算坐标绘制直线。</li></ol></li></ol><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="方法一-1"><a href="#方法一-1" class="headerlink" title="方法一"></a>方法一</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function">RNG <span class="title">rng</span><span class="params">(<span class="number">12345</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DetectRoadLine</span><span class="params">(Mat&amp; frame)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">//VideoCapture capture(&quot;G:\\opencv-python-image\\images\\lane.avi&quot;);</span></span><br><span class="line"><span class="comment">//VideoCapture capture(&quot;C:\\Users\\Obito\\Desktop\\project_video.mp4&quot;);</span></span><br><span class="line"><span class="function">VideoCapture <span class="title">capture</span><span class="params">(<span class="string">&quot;C:\\Users\\Obito\\Desktop\\1.mp4&quot;</span>)</span></span>;</span><br><span class="line"><span class="keyword">if</span> (!capture.<span class="built_in">isOpened</span>())</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;could not load video file!&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="built_in">system</span>(<span class="string">&quot;pause&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Mat frame;</span><br><span class="line"><span class="keyword">while</span> (capture.<span class="built_in">read</span>(frame))</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> key = <span class="built_in">waitKey</span>(<span class="number">100</span>);</span><br><span class="line"><span class="keyword">if</span> (key == <span class="number">27</span>)</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;BeforeProcessed&quot;</span>, frame);</span><br><span class="line"><span class="built_in">DetectRoadLine</span>(frame);</span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;AfterProcessed&quot;</span>, frame);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">waitKey</span>(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DetectRoadLine</span><span class="params">(Mat&amp; frame)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">// 这里的取参数要根据不同视频进行调整，主要就是提取出车道线</span></span><br><span class="line"><span class="type">int</span> offx = frame.cols / <span class="number">5</span>;</span><br><span class="line"><span class="type">int</span> offy = frame.rows / <span class="number">3</span>;</span><br><span class="line">Rect rect;</span><br><span class="line">rect.x = offx + <span class="number">30</span>;</span><br><span class="line">rect.y = frame.rows - offy - <span class="number">20</span>;</span><br><span class="line">rect.width = frame.cols - offx * <span class="number">1.5</span>;</span><br><span class="line">rect.height = offy - <span class="number">50</span>;</span><br><span class="line"></span><br><span class="line">Mat copy = <span class="built_in">frame</span>(rect).<span class="built_in">clone</span>();<span class="comment">// 截取出来</span></span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;copy&quot;</span>, copy);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 去除噪声 灰度处理 二值化</span></span><br><span class="line">Mat gray, binary;</span><br><span class="line"><span class="built_in">GaussianBlur</span>(copy, copy, <span class="built_in">Size</span>(<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>);</span><br><span class="line"><span class="built_in">cvtColor</span>(copy, gray, COLOR_BGR2GRAY);</span><br><span class="line"><span class="built_in">threshold</span>(gray, binary, <span class="number">0</span>, <span class="number">255</span>, THRESH_BINARY | THRESH_OTSU); <span class="comment">// 自适应阈值二值化</span></span><br><span class="line"><span class="comment">//Canny(gray, binary, 50, 150);</span></span><br><span class="line"><span class="comment">//imshow(&quot;binary&quot;, binary);</span></span><br><span class="line"></span><br><span class="line">Mat mask = Mat::<span class="built_in">zeros</span>(frame.<span class="built_in">size</span>(), CV_8UC1);</span><br><span class="line">binary.<span class="built_in">copyTo</span>(<span class="built_in">mask</span>(rect));</span><br><span class="line"></span><br><span class="line">vector&lt;vector&lt;Point&gt;&gt; contours;</span><br><span class="line">vector&lt;Vec4i&gt;hierarchy;</span><br><span class="line"><span class="comment">// 提取所有轮廓 每个轮廓只保留一些重要的坐标</span></span><br><span class="line"><span class="built_in">findContours</span>(mask, contours, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE, <span class="built_in">Point</span>(<span class="number">0</span>, <span class="number">0</span>));</span><br><span class="line">Mat drawing = Mat::<span class="built_in">zeros</span>(mask.<span class="built_in">size</span>(), CV_8UC3);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; contours.<span class="built_in">size</span>(); i++)</span><br><span class="line">&#123;</span><br><span class="line">RotatedRect rrt = <span class="built_in">minAreaRect</span>(contours[i]); <span class="comment">// 最小外接矩形 车道线相对其他物体向小</span></span><br><span class="line"><span class="comment">// RotatedRect类对象有三个重要属性: 矩形质心 边长（长宽） 旋转角度</span></span><br><span class="line"><span class="type">int</span> angle = <span class="built_in">abs</span>(rrt.angle);</span><br><span class="line"><span class="keyword">if</span> (angle &lt; <span class="number">20</span> || angle &gt; <span class="number">160</span> || angle == <span class="number">90</span>) <span class="comment">// 旋转角度再0 90 180 附近，矩形就成了一个直立的矩形</span></span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;rrt.angle: %.2f\n&quot;</span>, rrt.angle);</span><br><span class="line"><span class="comment">/*Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));</span></span><br><span class="line"><span class="comment">drawContours(frame, contours, (int)i, color, 2, 8, hierarchy, 0, Point());*/</span></span><br><span class="line"><span class="comment">/*cout &lt;&lt; &quot;contours.size&quot; &lt;&lt; contours.size() &lt;&lt; endl;</span></span><br><span class="line"><span class="comment">cout &lt;&lt; &quot;contours[i].size&quot; &lt;&lt; contours[i].size() &lt;&lt; endl;*/</span></span><br><span class="line"><span class="function">Point <span class="title">pt1</span><span class="params">(<span class="number">-1</span>, <span class="number">-1</span>)</span></span>;</span><br><span class="line"><span class="function">Point <span class="title">pt2</span><span class="params">(<span class="number">-1</span>, <span class="number">-1</span>)</span></span>;</span><br><span class="line"><span class="type">int</span> miny = <span class="number">10000</span>;</span><br><span class="line"><span class="type">int</span> maxy = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; contours[i].<span class="built_in">size</span>(); p++) <span class="comment">// 找出每个轮廓内的最小和最大的y值所对应的坐标，后面可以画线</span></span><br><span class="line">&#123;</span><br><span class="line">Point tmp = contours[i][p];</span><br><span class="line"><span class="keyword">if</span> (miny &gt; tmp.y)</span><br><span class="line">&#123;</span><br><span class="line">miny = tmp.y;</span><br><span class="line">pt1 = tmp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (maxy &lt; tmp.y)</span><br><span class="line">&#123;</span><br><span class="line">maxy = tmp.y;</span><br><span class="line">pt2 = tmp;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (pt1.x &lt; <span class="number">0</span> || pt2.x &lt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;line Point1 (x = %d, y = %d) to Point2 (x=%d, y=%d)\n&quot;</span>, pt1.x, pt1.y, pt2.x, pt2.y);</span><br><span class="line"><span class="built_in">line</span>(frame, pt1, pt2, <span class="built_in">Scalar</span>(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">3</span>, <span class="number">8</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;mask&quot;</span>, mask);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="方法二-1"><a href="#方法二-1" class="headerlink" title="方法二"></a>方法二</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">double</span> slope_th = <span class="number">0.3</span>;<span class="comment">// 直线斜率阈值</span></span><br><span class="line"><span class="type">double</span> canny_threshold1 = <span class="number">120</span>;</span><br><span class="line"><span class="type">double</span> canny_threshold2 = <span class="number">200</span>;</span><br><span class="line"></span><br><span class="line"><span class="function">RNG <span class="title">rng</span><span class="params">(<span class="number">12345</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DetectRoadLine</span><span class="params">(Mat&amp; frame)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">//VideoCapture capture(&quot;G:\\opencv-python-image\\images\\lane.avi&quot;);</span></span><br><span class="line"><span class="comment">//VideoCapture capture(&quot;C:\\Users\\Obito\\Desktop\\project_video.mp4&quot;);</span></span><br><span class="line"><span class="function">VideoCapture <span class="title">capture</span><span class="params">(<span class="string">&quot;C:\\Users\\Obito\\Desktop\\1.mp4&quot;</span>)</span></span>;</span><br><span class="line"><span class="keyword">if</span> (!capture.<span class="built_in">isOpened</span>())</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;could not load video file!&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="built_in">system</span>(<span class="string">&quot;pause&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Mat frame;</span><br><span class="line"><span class="keyword">while</span> (capture.<span class="built_in">read</span>(frame))</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> key = <span class="built_in">waitKey</span>(<span class="number">100</span>);</span><br><span class="line"><span class="keyword">if</span> (key == <span class="number">27</span>)</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;BeforeProcessed&quot;</span>, frame);</span><br><span class="line"><span class="built_in">DetectRoadLine</span>(frame);</span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;AfterProcessed&quot;</span>, frame);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">waitKey</span>(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DetectRoadLine</span><span class="params">(Mat&amp; frame)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">// 这里的取参数要根据不同视频进行调整，主要就是提取出车道线区域</span></span><br><span class="line"><span class="type">int</span> offx = frame.cols / <span class="number">5</span>;</span><br><span class="line"><span class="type">int</span> offy = frame.rows / <span class="number">3</span>;</span><br><span class="line">Rect rect;</span><br><span class="line">rect.x = offx + <span class="number">50</span>;</span><br><span class="line">rect.y = frame.rows - offy ;</span><br><span class="line">rect.width = frame.cols - offx * <span class="number">2</span>;</span><br><span class="line">rect.height = offy - <span class="number">50</span>;</span><br><span class="line"></span><br><span class="line">Mat copy = <span class="built_in">frame</span>(rect).<span class="built_in">clone</span>();<span class="comment">// 截取出来</span></span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;copy&quot;</span>, copy);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 去除噪声 灰度处理 二值化</span></span><br><span class="line">Mat gray, canny;</span><br><span class="line"><span class="built_in">cvtColor</span>(copy, gray, COLOR_BGR2GRAY);</span><br><span class="line"><span class="built_in">Canny</span>(gray, canny, canny_threshold1, canny_threshold2);</span><br><span class="line"><span class="built_in">imshow</span>(<span class="string">&quot;canny&quot;</span>, canny);</span><br><span class="line"></span><br><span class="line">Mat mask = Mat::<span class="built_in">zeros</span>(frame.<span class="built_in">size</span>(), CV_8UC1);</span><br><span class="line">canny.<span class="built_in">copyTo</span>(<span class="built_in">mask</span>(rect));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 霍夫直线检测</span></span><br><span class="line">vector&lt;Vec4i&gt; lines;</span><br><span class="line"><span class="built_in">HoughLinesP</span>(mask, lines, <span class="number">2</span>, CV_PI / <span class="number">180</span>, <span class="number">50</span>, <span class="number">20</span>, <span class="number">50</span>);</span><br><span class="line"></span><br><span class="line">vector&lt;<span class="type">double</span>&gt; slope_all; <span class="comment">// 存放斜率</span></span><br><span class="line">vector&lt;Vec4i&gt; tmp_line, left, right; <span class="comment">// tmp_line 存放筛选斜率后的直线 left、right则是进一步分类存储 Vec4i类型 x1 x2 y1 y2</span></span><br><span class="line">vector&lt;Point&gt; left_point, right_point; <span class="comment">// 存放两边直线的坐标 Point类型</span></span><br><span class="line">Point pt1, pt2;</span><br><span class="line"><span class="comment">// 根据斜率筛选直线</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> i : lines)</span><br><span class="line">&#123;</span><br><span class="line">pt1 = <span class="built_in">Point</span>(i[<span class="number">0</span>], i[<span class="number">1</span>]);</span><br><span class="line">pt2 = <span class="built_in">Point</span>(i[<span class="number">2</span>], i[<span class="number">3</span>]);</span><br><span class="line"></span><br><span class="line"><span class="type">double</span> slope = (<span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(pt1.y) - <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(pt2.y)) / (<span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(pt1.x) - <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(pt2.x));</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">abs</span>(slope) &gt; slope_th)</span><br><span class="line">&#123;</span><br><span class="line">slope_all.<span class="built_in">push_back</span>(slope);</span><br><span class="line">tmp_line.<span class="built_in">push_back</span>(i);</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;slope:&quot;</span> &lt;&lt; slope &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 进行左右边直线区分</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; tmp_line.<span class="built_in">size</span>(); i++)</span><br><span class="line">&#123;</span><br><span class="line">pt1 = <span class="built_in">Point</span>(tmp_line[i][<span class="number">0</span>], tmp_line[i][<span class="number">1</span>]);</span><br><span class="line">pt2 = <span class="built_in">Point</span>(tmp_line[i][<span class="number">2</span>], tmp_line[i][<span class="number">3</span>]);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (slope_all[i] &gt; <span class="number">0</span> &amp;&amp; pt1.x &gt; (frame.cols / <span class="number">2</span>) &amp;&amp; pt2.x &gt; (frame.cols / <span class="number">2</span>))</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 斜率大于0且 x坐标在图像中线右边 归为右边车道线 注意：opencv的图像y轴是朝下</span></span><br><span class="line">right.<span class="built_in">push_back</span>(tmp_line[i]);</span><br><span class="line">right_point.<span class="built_in">push_back</span>(pt1);</span><br><span class="line">right_point.<span class="built_in">push_back</span>(pt2);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (slope_all[i] &lt; <span class="number">0</span> &amp;&amp; pt1.x &lt; (frame.cols / <span class="number">2</span>) &amp;&amp; pt2.x &lt; (frame.cols / <span class="number">2</span>))</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 斜率小于0且 x坐标在图像中线左边 归为左边车道线 注意：opencv的图像y轴是朝下</span></span><br><span class="line">left.<span class="built_in">push_back</span>(tmp_line[i]);</span><br><span class="line">left_point.<span class="built_in">push_back</span>(pt1);</span><br><span class="line">left_point.<span class="built_in">push_back</span>(pt2);</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;left_point.size:&quot;</span> &lt;&lt; left_point.<span class="built_in">size</span>() &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;right_point.size:&quot;</span> &lt;&lt; right_point.<span class="built_in">size</span>() &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Vec4f left_line, right_line;</span><br><span class="line"><span class="comment">// 规定两个线的y值 初始y为最底，然后延长150</span></span><br><span class="line"><span class="type">int</span> y1 = frame.rows;</span><br><span class="line"><span class="type">int</span> y2 = y1 - <span class="number">150</span>;</span><br><span class="line"><span class="type">int</span> x1_right, x2_right, x1_left, x2_left;</span><br><span class="line"><span class="keyword">if</span> (left_point.<span class="built_in">size</span>() != <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 最小二乘法拟合直线</span></span><br><span class="line"><span class="built_in">fitLine</span>(left_point, left_line, DIST_L2, <span class="number">0</span>, <span class="number">0.01</span>, <span class="number">0.01</span>);</span><br><span class="line"><span class="type">double</span> left_k = left_line[<span class="number">1</span>] / left_line[<span class="number">0</span>];</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;左侧车道线斜率: &quot;</span> &lt;&lt; left_k &lt;&lt; endl;</span><br><span class="line"><span class="comment">// 由 y = k(x - x0) + y0 可得 x = (y - y0) / k + x</span></span><br><span class="line">x1_left = ((y1 - <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(left_line[<span class="number">3</span>])) / left_k + <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(left_line[<span class="number">2</span>]));</span><br><span class="line">x2_left = ((y2 - <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(left_line[<span class="number">3</span>])) / left_k + <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(left_line[<span class="number">2</span>]));</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;x1_left:&quot;</span> &lt;&lt; x1_left &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;x2_left:&quot;</span> &lt;&lt; x2_left &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;left_line[2]:&quot;</span> &lt;&lt; left_line[<span class="number">2</span>] &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;left_line[3]:&quot;</span> &lt;&lt; left_line[<span class="number">3</span>] &lt;&lt; endl;</span><br><span class="line"><span class="comment">// 画右边车道线</span></span><br><span class="line"><span class="built_in">line</span>(frame, <span class="built_in">Point</span>(x1_left, y1), <span class="built_in">Point</span>(x2_left, y2), <span class="built_in">Scalar</span>(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">8</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (right_point.<span class="built_in">size</span>() != <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 最小二乘法拟合直线</span></span><br><span class="line"><span class="built_in">fitLine</span>(right_point, right_line, DIST_L2, <span class="number">0</span>, <span class="number">0.01</span>, <span class="number">0.01</span>);</span><br><span class="line"><span class="type">double</span> right_k = right_line[<span class="number">1</span>] / right_line[<span class="number">0</span>];</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;右侧车道线斜率: &quot;</span> &lt;&lt; right_k &lt;&lt; endl;</span><br><span class="line"><span class="comment">// 由 y = k(x - x0) + y0 可得 x = (y - y0) / k + x</span></span><br><span class="line">x1_right = ((y1 - <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(right_line[<span class="number">3</span>])) / right_k + <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(right_line[<span class="number">2</span>]));</span><br><span class="line">x2_right = ((y2 - <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(right_line[<span class="number">3</span>])) / right_k + <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(right_line[<span class="number">2</span>]));</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;x1_right:&quot;</span> &lt;&lt; x1_right &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;x2_right:&quot;</span> &lt;&lt; x2_right &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;right_line[2]:&quot;</span> &lt;&lt; right_line[<span class="number">2</span>] &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;right_line[3]:&quot;</span> &lt;&lt; right_line[<span class="number">3</span>] &lt;&lt; endl;</span><br><span class="line"><span class="comment">// 画右边车道线</span></span><br><span class="line"><span class="built_in">line</span>(frame, <span class="built_in">Point</span>(x1_right, y1), <span class="built_in">Point</span>(x2_right, y2), <span class="built_in">Scalar</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">8</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><p>两个方法相比较下，第二个方法更优；</p><p>首先方法一只是单纯截取了ROI区域然后进行简单的二值化处理，当ROI区域内有很多其他噪声，效果会很差；方法二采用了Canny边缘检测，很好的去除了一些无关信息，能够有效的提取车道线轮廓。</p><p>其次方法二采用了霍夫直线检测加上最小二乘法拟合，可以更好地绘制出车道线；而方法一只是对轮廓内的坐标点进行最值判断，直接根据最大值和最小值画出直线，可能会不准，并且是对轮廓进行遍历，因此会同时出现多条直线的情况。</p><h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><ol><li>根据车道位置对ROI区域的提取，便于后续的操作。</li><li>边缘检测时的阈值大小。</li><li>霍夫直线检测时斜率的判断。</li><li>根据不同函数对vector容器类型的选择。</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p><a href="https://blog.csdn.net/Zero___Chen/article/details/119666454">OpenCV C++案例实战一《车道检测》_车道线检测c++_Zero___Chen的博客-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/60891432">基于OpenCV的车道线检测算法(Traditional Method) - 知乎 (zhihu.com)</a></p><p><a href="https://blog.csdn.net/Zero___Chen/article/details/119666454">https://blog.csdn.net/Zero___Chen/article/details/119666454</a></p><p><a href="https://blog.csdn.net/qq_45009980/article/details/106986428">c++ 车道线检测_c++车道线代码实现_majinbuu鲸落的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/leonardohaig/article/details/87907462">霍夫变换直线检测（Line Detection）原理及示例_霍夫变换直线检测原理_leonardohaig的博客-CSDN博客</a></p><p>[【OpenCV入门教程之十四】OpenCV霍夫变换：霍夫线变换，霍夫圆变换合辑_<a href="https://blog.csdn.net/poem_qianmo/article/details/26977557">1][原]【opencv入门教程之十四】opencv霍夫变换:霍夫线变换,霍夫圆变换合辑_浅墨_毛星云的博客-CSDN博客</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于Opencv的车道线检测&quot;&gt;&lt;a href=&quot;#基于Opencv的车道线检测&quot; class=&quot;headerlink&quot; title=&quot;基于Opencv的车道线检测&quot;&gt;&lt;/a&gt;基于Opencv的车道线检测&lt;/h1&gt;&lt;h2 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言</summary>
      
    
    
    
    <category term="图像处理" scheme="http://example.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
    <category term="opencv" scheme="http://example.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/opencv/"/>
    
    
    <category term="opencv" scheme="http://example.com/tags/opencv/"/>
    
  </entry>
  
  <entry>
    <title>神之眼</title>
    <link href="http://example.com/2023/08/01/%E7%A5%9E%E4%B9%8B%E7%9C%BC/"/>
    <id>http://example.com/2023/08/01/%E7%A5%9E%E4%B9%8B%E7%9C%BC/</id>
    <published>2023-08-01T10:16:26.000Z</published>
    <updated>2023-08-07T10:00:50.633Z</updated>
    
    
    
    
    <category term="硬件" scheme="http://example.com/categories/%E7%A1%AC%E4%BB%B6/"/>
    
    <category term="焊接" scheme="http://example.com/categories/%E7%A1%AC%E4%BB%B6/%E7%84%8A%E6%8E%A5/"/>
    
    
    <category term="esp" scheme="http://example.com/tags/esp/"/>
    
    <category term="esp32" scheme="http://example.com/tags/esp32/"/>
    
  </entry>
  
  <entry>
    <title>移植u8g2库到stm32</title>
    <link href="http://example.com/2023/05/21/%E7%A7%BB%E6%A4%8Du8g2%E5%BA%93%E5%88%B0stm32/"/>
    <id>http://example.com/2023/05/21/%E7%A7%BB%E6%A4%8Du8g2%E5%BA%93%E5%88%B0stm32/</id>
    <published>2023-05-21T05:48:01.000Z</published>
    <updated>2023-08-07T09:57:59.714Z</updated>
    
    <content type="html"><![CDATA[<h1 id="抑制u8g2库到stm32-标准库"><a href="#抑制u8g2库到stm32-标准库" class="headerlink" title="抑制u8g2库到stm32(标准库)"></a>抑制u8g2库到stm32(标准库)</h1><h2 id="移植u8g2库到stm32-标准库"><a href="#移植u8g2库到stm32-标准库" class="headerlink" title="移植u8g2库到stm32(标准库)"></a>移植u8g2库到stm32(标准库)</h2><p>实验硬件：</p><ul><li>STM32F103ZE</li><li>OLED：0.96寸OLED，IIC接口</li></ul><p>U8g2 是一个用于嵌入式设备的单色图形库。U8g2支持单色OLED和LCD，并支持如SSD1306等多种类型的OLED驱动。</p><p>U8g2源码的开源库地址：<a href="https://github.com/olikraus/u8g2">https://github.com/olikraus/u8g2</a> </p><h2 id="移植步骤"><a href="#移植步骤" class="headerlink" title="移植步骤"></a>移植步骤</h2><ol><li>从官网下载 u8g2 的源码；</li><li>只移植c语言版本，因而只需要将用到 <strong>csrc文件夹内的文件</strong>；</li><li>找到需要对应的驱动文件（u8x8_d_xxx.c），<strong>只需要添加一个型号</strong>即可，这里我用到的是 u8x8_d_ssd1306_128x64_noname.c 文件，然后其余的型号可以删除掉（格式一般都为 u8x8_d_xxx.c）</li><li><strong>修改 u8g2_d_setup.c 文件</strong>，找到对应 OLED型号的函数，这里用到的是u8g2_Setup_ssd1306_i2c_128x64_noname_f ，保留这个函数，其他删除掉或者注释掉。</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;u8g2.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* ssd1306 f */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">u8g2_Setup_ssd1306_i2c_128x64_noname_f</span><span class="params">(<span class="type">u8g2_t</span> *u8g2, <span class="type">const</span> <span class="type">u8g2_cb_t</span> *rotation, u8x8_msg_cb byte_cb, u8x8_msg_cb gpio_and_delay_cb)</span></span><br><span class="line">&#123;</span><br><span class="line">     <span class="type">uint8_t</span> tile_buf_height;</span><br><span class="line">     <span class="type">uint8_t</span> *buf;</span><br><span class="line">     u8g2_SetupDisplay(u8g2, u8x8_d_ssd1306_128x64_noname,  u8x8_cad_ssd13xx_fast_i2c, byte_cb, gpio_and_delay_cb);</span><br><span class="line">     buf = u8g2_m_16_8_f(&amp;tile_buf_height);</span><br><span class="line">     u8g2_SetupBuffer(u8g2, buf, tile_buf_height, u8g2_ll_hvline_vertical_top_lsb, rotation);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>其中类似跟这个函数类似的有：</p><ul><li><p>u8g2_Setup_ssd1306_i2c_128x64_noname_1</p></li><li><p>u8g2_Setup_ssd1306_i2c_128x64_noname_2</p></li><li><p>u8g2_Setup_ssd1306_i2c_128x64_noname_f</p></li></ul><p>函数后面的数字或字母表示显示时 buf 的大小：</p><ul><li>1：128字节</li><li>2：256字节</li><li>f：1024字节</li></ul><ol start="5"><li><strong>修改 u8g2_d_memory.c 文件</strong>，查找 u8g2_d_setup.c 文件内保留的函数(u8g2_Setup_ssd1306_i2c_128x64_noname_f) 中 赋值 buf 调用到的函数（u8g2_m_16_8_f），然后将 u8g2_d_memory.c 文件中的其他函数都删除或注释掉，只保留赋值 buf 调用到的函数（u8g2_m_16_8_f）。</li><li>将修改完的 csrc文件夹添加到工程中。</li><li>将编译器的<strong>优化级别调整为 -O2或-O3</strong>，否则还是会因为字体的原因出现链接时空间不足的问题。</li></ol><h2 id="测试-u8g2库移植是否成功"><a href="#测试-u8g2库移植是否成功" class="headerlink" title="测试 u8g2库移植是否成功"></a>测试 u8g2库移植是否成功</h2><h3 id="创建一个头文件"><a href="#创建一个头文件" class="headerlink" title="创建一个头文件"></a>创建一个头文件</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> __U8G2_OLED_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __U8G2_OLED_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;stm32f10x.h&quot;</span>                  <span class="comment">// Device header</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;u8g2.h&quot;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">IIC_Init</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"><span class="type">uint8_t</span> <span class="title function_">u8x8_gpio_and_delay</span><span class="params">(<span class="type">u8x8_t</span> *u8x8, <span class="type">uint8_t</span> msg, <span class="type">uint8_t</span> arg_int, <span class="type">void</span> *arg_ptr)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">u8g2Init</span><span class="params">(<span class="type">u8g2_t</span> *u8g2)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">draw</span><span class="params">(<span class="type">u8g2_t</span> *u8g2)</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="GPIO初始化"><a href="#GPIO初始化" class="headerlink" title="GPIO初始化"></a>GPIO初始化</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;u8g2_oled.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SCL_Pin GPIO_Pin_6</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SDA_Pin GPIO_Pin_7</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> IIC_GPIO_Port GPIOB</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">IIC_Init</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">GPIO_InitTypeDef GPIO_InitStructure;</span><br><span class="line">RCC_APB2PeriphClockCmd( RCC_APB2Periph_GPIOB, ENABLE );</span><br><span class="line"></span><br><span class="line">GPIO_InitStructure.GPIO_Pin = SCL_Pin|SDA_Pin;</span><br><span class="line">GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP ;   <span class="comment">//推挽输出</span></span><br><span class="line">GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz;</span><br><span class="line">GPIO_Init(IIC_GPIO_Port, &amp;GPIO_InitStructure);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h3 id="u8x8-gpio-and-delay"><a href="#u8x8-gpio-and-delay" class="headerlink" title="u8x8_gpio_and_delay"></a>u8x8_gpio_and_delay</h3><p>在 u8g2 的构造函数中，需要应用程序传入一个函数指针，u8g2 库将通过这个函数指针来调用这个函数，这个函数用来现延时，IO口的控制等等。</p><p>赋予U8g2相应的<strong>延时函数</strong>，比如下面的delay_ms和delay_us</p><p>为U8g2提供IIC接口的高低电平调用:</p><ul><li><p>U8x8_MSG_GPIO_I2C_CLOCK：IIC 的 SCL</p></li><li><p>U8x8_MSG_GPIO_I2C_DATA：IIC 的 SDA</p></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">uint8_t</span> <span class="title function_">u8x8_gpio_and_delay</span><span class="params">(<span class="type">u8x8_t</span> *u8x8, <span class="type">uint8_t</span> msg, <span class="type">uint8_t</span> arg_int, <span class="type">void</span> *arg_ptr)</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">switch</span> (msg)</span><br><span class="line">   &#123;</span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_DELAY_100NANO: <span class="comment">// delay arg_int * 100 nano seconds</span></span><br><span class="line">       __NOP();</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_DELAY_10MICRO: <span class="comment">// delay arg_int * 10 micro seconds</span></span><br><span class="line">       <span class="keyword">for</span> (<span class="type">uint16_t</span> n = <span class="number">0</span>; n &lt; <span class="number">320</span>; n++)</span><br><span class="line">       &#123;</span><br><span class="line">           __NOP();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_DELAY_MILLI: <span class="comment">// delay arg_int * 1 milli second</span></span><br><span class="line">       delay_ms(<span class="number">1</span>);</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_DELAY_I2C: <span class="comment">// arg_int is the I2C speed in 100KHz, e.g. 4 = 400 KHz</span></span><br><span class="line">       delay_us(<span class="number">5</span>);</span><br><span class="line">       <span class="keyword">break</span>;                    <span class="comment">// arg_int=1: delay by 5us, arg_int = 4: delay by 1.25us</span></span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_GPIO_I2C_CLOCK: <span class="comment">// arg_int=0: Output low at I2C clock pin</span></span><br><span class="line"> <span class="keyword">if</span>(arg_int == <span class="number">1</span>)</span><br><span class="line"> &#123;</span><br><span class="line">  GPIO_SetBits(IIC_GPIO_Port, SCL_Pin);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(arg_int == <span class="number">0</span>)</span><br><span class="line"> &#123;</span><br><span class="line">  GPIO_ResetBits(IIC_GPIO_Port, SCL_Pin);</span><br><span class="line"> &#125;</span><br><span class="line">       <span class="keyword">break</span>;                    <span class="comment">// arg_int=1: Input dir with pullup high for I2C clock pin</span></span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_GPIO_I2C_DATA:  <span class="comment">// arg_int=0: Output low at I2C data pin</span></span><br><span class="line">       <span class="keyword">if</span>(arg_int == <span class="number">1</span>)</span><br><span class="line"> &#123;</span><br><span class="line">  GPIO_SetBits(IIC_GPIO_Port, SDA_Pin);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(arg_int == <span class="number">0</span>)</span><br><span class="line"> &#123;</span><br><span class="line">  GPIO_ResetBits(IIC_GPIO_Port, SDA_Pin);</span><br><span class="line"> &#125;</span><br><span class="line">       <span class="keyword">break</span>;                    <span class="comment">// arg_int=1: Input dir with pullup high for I2C data pin</span></span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_GPIO_MENU_SELECT:</span><br><span class="line">       u8x8_SetGPIOResult(u8x8, <span class="comment">/* get menu select pin state */</span> <span class="number">0</span>);</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_GPIO_MENU_NEXT:</span><br><span class="line">       u8x8_SetGPIOResult(u8x8, <span class="comment">/* get menu next pin state */</span> <span class="number">0</span>);</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_GPIO_MENU_PREV:</span><br><span class="line">       u8x8_SetGPIOResult(u8x8, <span class="comment">/* get menu prev pin state */</span> <span class="number">0</span>);</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> U8X8_MSG_GPIO_MENU_HOME:</span><br><span class="line">       u8x8_SetGPIOResult(u8x8, <span class="comment">/* get menu home pin state */</span> <span class="number">0</span>);</span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">default</span>:</span><br><span class="line">       u8x8_SetGPIOResult(u8x8, <span class="number">1</span>); <span class="comment">// default return value</span></span><br><span class="line">       <span class="keyword">break</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="u8g2Init"><a href="#u8g2Init" class="headerlink" title="u8g2Init"></a>u8g2Init</h3><p>U8g2的初始化，根据上面用到的函数进行调用，这里我需要调用下面这个 <strong>u8g2_Setup_ssd1306_128x64_noname_f</strong>函数，该函数的4个参数含义：</p><ul><li><p><strong>u8g2</strong>：传入的U8g2结构体</p></li><li><p><strong>U8G2_R0</strong>：默认使用U8G2_R0即可（用于配置屏幕是否要旋转）</p></li><li><p><strong>u8x8_byte_sw_i2c</strong>：使用软件IIC驱动，该函数由U8g2源码提供</p></li><li><p><strong>u8x8_gpio_and_delay</strong>：就是上面我们写的配置函数</p></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">u8g2Init</span><span class="params">(<span class="type">u8g2_t</span> *u8g2)</span></span><br><span class="line">&#123;</span><br><span class="line">    u8g2_Setup_ssd1306_i2c_128x64_noname_f(u8g2, U8G2_R0, u8x8_byte_sw_i2c, u8x8_gpio_and_delay);  <span class="comment">// 初始化 u8g2 结构体</span></span><br><span class="line">    u8g2_InitDisplay(u8g2); <span class="comment">// 根据所选的芯片进行初始化工作，初始化完成后，显示器处于关闭状态</span></span><br><span class="line">    u8g2_SetPowerSave(u8g2, <span class="number">0</span>); <span class="comment">// 打开显示器</span></span><br><span class="line">    u8g2_ClearBuffer(u8g2);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h3 id="显示测试函数-draw"><a href="#显示测试函数-draw" class="headerlink" title="显示测试函数 draw"></a>显示测试函数 draw</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">draw</span><span class="params">(<span class="type">u8g2_t</span> *u8g2)</span></span><br><span class="line">&#123;</span><br><span class="line">   u8g2_SetFontMode(u8g2, <span class="number">1</span>); <span class="comment">/*字体模式选择*/</span></span><br><span class="line">   u8g2_SetFontDirection(u8g2, <span class="number">0</span>); <span class="comment">/*字体方向选择*/</span></span><br><span class="line">   u8g2_SetFont(u8g2, u8g2_font_inb24_mf); <span class="comment">/*字库选择*/</span></span><br><span class="line">   u8g2_DrawStr(u8g2, <span class="number">0</span>, <span class="number">20</span>, <span class="string">&quot;U&quot;</span>);</span><br><span class="line"></span><br><span class="line">   u8g2_SetFontDirection(u8g2, <span class="number">1</span>);</span><br><span class="line">   u8g2_SetFont(u8g2, u8g2_font_inb30_mn);</span><br><span class="line">   u8g2_DrawStr(u8g2, <span class="number">21</span>,<span class="number">8</span>,<span class="string">&quot;8&quot;</span>);</span><br><span class="line"></span><br><span class="line">   u8g2_SetFontDirection(u8g2, <span class="number">0</span>);</span><br><span class="line">   u8g2_SetFont(u8g2, u8g2_font_inb24_mf);</span><br><span class="line">   u8g2_DrawStr(u8g2, <span class="number">51</span>,<span class="number">30</span>,<span class="string">&quot;g&quot;</span>);</span><br><span class="line">   u8g2_DrawStr(u8g2, <span class="number">67</span>,<span class="number">30</span>,<span class="string">&quot;\xb2&quot;</span>);</span><br><span class="line"></span><br><span class="line">   u8g2_DrawHLine(u8g2, <span class="number">2</span>, <span class="number">35</span>, <span class="number">47</span>);</span><br><span class="line">   u8g2_DrawHLine(u8g2, <span class="number">3</span>, <span class="number">36</span>, <span class="number">47</span>);![image<span class="number">-20230802221013234</span>](./C:/Users/Obito/AppData/Roaming/Typora/typora-user-images/image<span class="number">-20230802221013234.</span>png)</span><br><span class="line">   u8g2_DrawVLine(u8g2, <span class="number">45</span>, <span class="number">32</span>, <span class="number">12</span>);</span><br><span class="line">   u8g2_DrawVLine(u8g2, <span class="number">46</span>, <span class="number">33</span>, <span class="number">12</span>);</span><br><span class="line"></span><br><span class="line">   u8g2_SetFont(u8g2, u8g2_font_4x6_tr);</span><br><span class="line">   u8g2_DrawStr(u8g2, <span class="number">1</span>,<span class="number">54</span>,<span class="string">&quot;github.com/olikraus/u8g2&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="显示效果"><a href="#显示效果" class="headerlink" title="显示效果"></a>显示效果</h2><p>最后编译完成烧录到 stm32即可，效果如下：</p><p><img src="/2023/05/21/%E7%A7%BB%E6%A4%8Du8g2%E5%BA%93%E5%88%B0stm32/U8g2.jpg" alt="U8g2"></p><blockquote><p><a href="https://www.bilibili.com/read/cv15875042">STM32移植U8g2图形库——玩转OLED显示 - 哔哩哔哩 (bilibili.com)</a></p><p><a href="https://www.codetd.com/article/9126596">stm32 u8g2移植笔记 - 代码天地 (codetd.com)</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;抑制u8g2库到stm32-标准库&quot;&gt;&lt;a href=&quot;#抑制u8g2库到stm32-标准库&quot; class=&quot;headerlink&quot; title=&quot;抑制u8g2库到stm32(标准库)&quot;&gt;&lt;/a&gt;抑制u8g2库到stm32(标准库)&lt;/h1&gt;&lt;h2 id=&quot;移植u</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://example.com/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    <category term="stm32" scheme="http://example.com/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/stm32/"/>
    
    
    <category term="stm32" scheme="http://example.com/tags/stm32/"/>
    
  </entry>
  
  <entry>
    <title>嵌入式实践实习知识</title>
    <link href="http://example.com/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/"/>
    <id>http://example.com/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/</id>
    <published>2023-05-19T09:25:01.000Z</published>
    <updated>2023-08-07T09:49:54.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="嵌入式实践实习知识"><a href="#嵌入式实践实习知识" class="headerlink" title="嵌入式实践实习知识"></a>嵌入式实践实习知识</h2><p>大二下时长一周半多半周的嵌入式实习，由粤嵌的工程师教授知识。</p><p>环境及工具：Ubuntu 18.04，arm-linux-gcc 5.4.0，粤嵌GEC6818开发板</p><p>以下是此次实习中get到的一下知识以及遇到的一些问题。</p><h3 id="2023-05-09"><a href="#2023-05-09" class="headerlink" title="2023.05.09"></a>2023.05.09</h3><p><strong>gcc :</strong> c语言编译器</p><p><strong>g++ :</strong> c++编译器</p><p><strong>gdb :</strong> c&#x2F;c++调试器</p><p><strong>binutils :</strong> 二进制工具集</p><p><strong>MinGW :</strong> MinGW 是让Windows 用户可以用上 GNU 工具，比如GCC。</p><p><strong>Cygwin :</strong> Cygwin 提供完整的类Unix 环境，Windows 用户不仅可以使用GNU 工具，理论上Linux 上的程序只要用Cygwin 重新编译，就可以在Windows 上运行。</p><ul><li>如果程序只用到C&#x2F;C++ 标准库，可以用MinGW 或Cygwin 编译。</li><li>如果程序还用到了<strong>POSIX API</strong>，则只能用Cygwin 编译。</li></ul><p><strong>cmd  输入 sysdm.cpl 打开环境变量设置</strong></p><p>cygwin64 和 MinGW 的 gcc 和 g++ 只能有一个能使用，不能同时使用。</p><p>通过修改环境变量的优先级 顺序从上到下，这里使用 cygwin64 的 gcc 和 g++ 如下：</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md3.png" alt="md3"></p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md01.png" alt="md01"></p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md02.png" alt="md02"></p><p>在Linux系统中，可执行文件没有统一的后缀，系统从文件的属性来区分可执行文件和不可执行文件。而gcc则通过后缀来区别输入文件的类别，下面介绍gcc所遵循的部分约定规则。</p><p>.c 为后缀的文件，C语言源代码文件；<br>.a 为后缀的文件，是由目标文件构成的库文件；<br>.C .cc 或 .cxx 为后缀的文件，是C++源代码文件；<br>.h 为后缀的文件，是程序所包含的头文件；<br>.i 为后缀的文件，是已经预处理过的C源代码文件；<br>.m 为后缀的文件，是Objective-C源代码文件；<br>.o 为后缀的文件，是编译后的目标文件；<br>.s 为后缀的文件，是汇编语言源代码文件；<br>.S 为后缀的文件，是经过预编译的汇编语言源代码文件</p><p><strong>sudo</strong>：super user do 超级用户执行 ；su：switch user 切换用户。</p><p><strong>sudo su</strong>：当前用户暂时申请 root 权限，输入的是当前用户密码。</p><p><strong>sudo -s</strong>：执行环境变数中的 SHELL 所指定的 shell ，或是 &#x2F;etc&#x2F;passwd 里所指定的 shell，输入当前用户的密码。</p><p><strong>su 用户名</strong>:：用户名为空时默认为 root 用户，申请切换 root 用户，<strong>需要 root 用户的密码</strong>，ubuntu 中<strong>默认没有设置 root 用户的密码，第一次使用需要自行设置</strong>，sudo passwd root 设置 root 用户密码。</p><p><strong>su -用户名</strong>： </p><ul><li><p>如果加入了 - 参数，那么是一种 login-shell 的方式，意思是说切换到另一个用户 <user_name> 之后，当前的 shell 会加载 <user_name> 对应的环境变量和各种设置；</p></li><li><p>如果没有加入 - 参数，那么是一种 <a href="https://www.zhihu.com/search?q=non-login-shell&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2553370274%7D">non-login-shell</a> 的方式，意思是说我现在切换到了 <user_name>，但是当前的 shell 还是加载切换之前的那个用户的环境变量以及各种设置。</p></li></ul><p>由下图可知，su 和 -su 都需要输入 root 用户的密码，<strong>su</strong> 执行后目录为<strong>当前用户的目录</strong>，**- su** 执行完后目录是<strong>根目录</strong>，两者都没有时间限制。</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md04.png" alt="md04"></p><p>由下图可知，使用 sudo 时输入的密码为当前用户的密码，sudo -s 执行后不加载用户变量，目录为当前目录 ，sudo -i 执行完目录为根目录，sudo su 这种用法好像可以舍弃。。。。</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md05.png" alt="md05"></p><p>另外，用户名的颜色即上面的绿色和灰色好像没什么作用，颜色可以通过命令修改。</p><p><strong>gcc 编译的文件</strong> or <strong>gcc 编译的文件 -o 生产的文件名</strong></p><p><strong>.&#x2F; 生成的文件名</strong> 即可输出信息。</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md06.png" alt="md06"></p><p><strong>df -h</strong> 查看内存</p><p><strong>ls -a</strong> 查看当前目录下的文件，相比直接 ls 还显示了隐藏文件。</p><p><strong>ls -l</strong> 查看某一个目录会得到一个7个字段的列表。</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md09.png" alt="md09"></p><p><strong>文件类型</strong></p><ul><li>-表示普通文件；</li><li>d 表示目录；</li><li>l 表示链接文件；</li><li>p 表示管理文件；</li><li>b 表示块设备文件；</li><li>c 表示字符设备文件；</li><li>s 表示套接字文件；</li></ul><p><strong>文件名称，字体颜色</strong></p><ul><li><p>如果是一个符号链接，那么会有一个 “-&gt;” 箭头符号，后面根一个它指向的文件名；</p></li><li><p>灰白色表示普通文件；</p></li><li><p>亮绿色表示可执行文件；</p></li><li><p>亮红色表示压缩文件；</p></li><li><p>灰蓝色表示目录；</p></li><li><p>亮蓝色表示链接文件；</p></li><li><p>亮黄色表示设备文件；</p></li></ul><p><strong>chmod 权限值 文件名</strong>：设置用户对文件的权限。</p><p>Linux&#x2F;Unix 的文件调用权限分为三级 : 文件所有者（Owner）、用户组（Group）、其它用户（Other Users）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ugoa...][[+-=][rwxX]...][,...]</span><br></pre></td></tr></table></figure><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md08.jpg" alt="md08"></p><p><strong>符号模式</strong></p><table><thead><tr><th align="center">who</th><th align="center">用户类型</th><th align="left">说明</th></tr></thead><tbody><tr><td align="center"><code>u</code></td><td align="center">user</td><td align="left">文件所有者</td></tr><tr><td align="center"><code>g</code></td><td align="center">group</td><td align="left">文件所有者所在组</td></tr><tr><td align="center"><code>o</code></td><td align="center">others</td><td align="left">所有其他用户</td></tr><tr><td align="center"><code>a</code></td><td align="center">all</td><td align="left">所有用户, 相当于 <em>ugo</em></td></tr></tbody></table><table><thead><tr><th align="center">Operator</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center"><code>+</code></td><td align="center">为指定的用户类型增加权限</td></tr><tr><td align="center"><code>-</code></td><td align="center">去除指定用户类型的权限</td></tr><tr><td align="center"><code>=</code></td><td align="center">设置指定用户权限的设置，即将用户类型的所有权限重新设置</td></tr></tbody></table><table><thead><tr><th align="center">模式</th><th align="center">名字</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center"><code>r</code></td><td align="center">读</td><td align="center">设置为可读权限</td></tr><tr><td align="center"><code>w</code></td><td align="center">写</td><td align="center">设置为可写权限</td></tr><tr><td align="center"><code>x</code></td><td align="center">执行权限</td><td align="center">设置为可执行权限</td></tr><tr><td align="center"><code>X</code></td><td align="center">特殊执行权限</td><td align="center">只有当文件为目录文件，或者其他类型的用户有可执行权限时，才将文件权限设置可执行</td></tr><tr><td align="center"><code>s</code></td><td align="center">setuid&#x2F;gid</td><td align="center">当文件被执行时，根据who参数指定的用户类型设置文件的setuid或者setgid权限</td></tr><tr><td align="center"><code>t</code></td><td align="center">粘贴位</td><td align="center">设置粘贴位，只有超级用户可以设置该位，只有文件所有者u可以使用该位</td></tr></tbody></table><p><strong>八进制语法</strong></p><p>文件或目录的权限位是由 9 个权限位来控制，每三位为一组。</p><table><thead><tr><th align="center">#</th><th align="center">权限</th><th align="center">rwx</th><th align="center">二进制</th></tr></thead><tbody><tr><td align="center">7</td><td align="center">读 + 写 + 执行</td><td align="center">rwx</td><td align="center">111</td></tr><tr><td align="center">6</td><td align="center">读 + 写</td><td align="center">rw-</td><td align="center">110</td></tr><tr><td align="center">5</td><td align="center">读 + 执行</td><td align="center">r-x</td><td align="center">101</td></tr><tr><td align="center"><strong>4</strong></td><td align="center"><strong>只读</strong></td><td align="center"><strong>r–</strong></td><td align="center">100</td></tr><tr><td align="center">3</td><td align="center">写 + 执行</td><td align="center">-wx</td><td align="center">011</td></tr><tr><td align="center"><strong>2</strong></td><td align="center"><strong>只写</strong></td><td align="center"><strong>-w-</strong></td><td align="center">010</td></tr><tr><td align="center"><strong>1</strong></td><td align="center"><strong>只执行</strong></td><td align="center"><strong>–x</strong></td><td align="center">001</td></tr><tr><td align="center"><strong>0</strong></td><td align="center"><strong>无</strong></td><td align="center"><strong>—</strong></td><td align="center">000</td></tr></tbody></table><p>eg：765 表示所有者的权限为 rwx(4+2+1)，用户组的权限为 rw(4+2+0)，其他用户的权限为 rx(4+0+1)。</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md07.png" alt="md07"></p><p><strong>tar -xvf xxx.tar.gz</strong> 文件目录 </p><p><strong>tar -zcvf xxx.tar.gz a.txt b.txt c.txt</strong> 将 a.txt b.txt c.txt 打包压缩为一个名为 xxx.tar.gz 压缩包。</p><p><strong>tar cvf xxx.tar xxx</strong>  打包一个tar</p><p><strong>tar xvf xxx.tar xxx</strong>    解开一个tar</p><p><strong>tar cvzf xxx.tar.gz xxx</strong> 打包压缩一个 tar</p><p><strong>tar zxvf xxx.tar.gz</strong>  解压一个tar</p><p><strong>tar -tf 误解压文件 | xargs rm -rf</strong>     </p><p><strong>tar -tf 是列出该压缩文件中的文件列表，xargs rm -rf 则是根据前面的文件列表来删除文件。</strong></p><p>在早期，Linux 和 Unix 系统用一种叫做 tar（Tape ARchive，磁带归档）的工具来打包文件。但它只能打包不能压缩。后来 gzip（GNU Zip）就出现了，通过将 tar 和 gzip 结合起来，形成 tar.gz 格式。</p><p>tar 格式在保留文件权限、所有权和时间戳。</p><h3 id="2023-5-10"><a href="#2023-5-10" class="headerlink" title="2023.5.10"></a>2023.5.10</h3><p>删除文件的骚操作：</p><p><strong>rm 文件1 文件2 …. 删除多个文件</strong></p><p>*<em>rm <em>.txt  删除 .txt 这一类文件</em></em></p><p><em><em>rm xxx</em> 删除固定字母开头的文件</em>*</p><p><strong>rm * -rf 删除文件夹下面所有文件</strong></p><p>Activator 软件，连接开发板，传输在 Ubuntu 下交叉编译后生成的文件到开发板的系统下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: rx 文件名</span><br><span class="line">然后将文件拖进去</span><br><span class="line">选择 Xmodem</span><br></pre></td></tr></table></figure><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md14.png" alt="md14"></p><p>执行文件时需要先查看文件是否可执行。执行以下命令让文件权限变为可读可写可执行文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 文件名</span><br></pre></td></tr></table></figure><h3 id="2023-5-11"><a href="#2023-5-11" class="headerlink" title="2023.5.11"></a>2023.5.11</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">man man 查看所有手册</span><br><span class="line">man -f open 可查看 open 关键字出现在哪些手册中</span><br><span class="line">man 2 open 在第二手册中查询 open 关键字</span><br></pre></td></tr></table></figure><p><strong>文件描述符本质</strong></p><p>函数 open() 的返回值，是一个整型 int 数据。这个整型数据，实际上是内核中的一个称为 fd_array 的数组的下标：</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md16.jpg" alt="md16"></p><p>打开文件时，内核产生一个指向 file{} 的指针，并将该指针放入一个位于 file_struct{} 中的数组fd_array[] 中，而该指针所在数组的下标，就被 open() 返回给用户，用户把这个数组下标称为文件描述符，如上图所示。</p><p>结论：</p><ul><li>文件描述符从 0 开始，每打开一个文件，就产生一个新的文件描述符（一般是<strong>返回一个最小未使用的描述符</strong>）。</li><li>可以<strong>重复打开</strong>同一个文件，每次打开文件都会使内核产生新结构体（每一个描述符拥有自己独立的资源互不影响），并<strong>得到不同</strong>的文件描述符。</li><li>由于系统在每个进程开始运行时，都默认打开了一次键盘、两次屏幕，<strong>因此0、1、2描述符分别代表标准输入、标准输出和标准出错三个文件（两个硬件）</strong>。</li></ul><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md17.jpg" alt="md17"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    // 1. 打开文件</span><br><span class="line">    // int open(const char *pathname, int flags);</span><br><span class="line">    int file_descriptor = open(&quot;test_open.txt&quot;, O_RDWR);</span><br><span class="line">    int file_descriptor1 = open(&quot;test_open.txt&quot;, O_RDWR);</span><br><span class="line">    // 1.1 判断是否打开成功</span><br><span class="line">    if (file_descriptor == -1)</span><br><span class="line">    &#123;</span><br><span class="line">        // printf(&quot;文件打开失败\n&quot;);</span><br><span class="line">        perror(&quot;文件打开失败\n&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line">    if (file_descriptor1 == -1)</span><br><span class="line">    &#123;</span><br><span class="line">        // printf(&quot;文件打开失败\n&quot;);</span><br><span class="line">        perror(&quot;文件打开失败\n&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;文件打开成功\n&quot;);</span><br><span class="line">    printf(&quot;%d\n&quot;,file_descriptor); // 3</span><br><span class="line">    printf(&quot;%d\n&quot;,file_descriptor1); // 4</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面可以得出虽然打开了同个文件，但是<strong>得到了不同</strong>文件描述。</p><p>在 Ubuntu 下直接 gcc 编译文件跟 arm-linux-gcc 编译文件是不一样的，后者为交叉编译。</p><p>GEC6818开发板屏幕的色深是 32 位的，32 位色深的屏幕一般被称为真彩屏，或 1600万色屏。色深决定了一个像素点所能表达的颜色的丰富程度，色深越大，色彩表现力越强。</p><p>虽然LCD设备本质上也可以看作是一个文件，在文件系统中有其对应的设备节点，可以像普通文件一样对其进行读写操作（read&#x2F;write），但由于对字符设备的读写操作是以字节流的方式进行的，因此除非操作的图像尺寸刚好与屏幕尺寸完全一致，如下图所示，图片的宽高与LCD的宽高完全一致，否则将会画面会乱。</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md15.png" alt="md15"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 1. 打开文件</span></span><br><span class="line">    <span class="comment">// int open(const char *pathname, int flags);</span></span><br><span class="line">    <span class="type">int</span> file_descriptor = open(<span class="string">&quot;/dev/fb0&quot;</span>, O_RDWR);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.1 判断是否打开成功</span></span><br><span class="line">    <span class="keyword">if</span> (file_descriptor == <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;文件打开失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;文件打开成功\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 配置颜色值 ARGB 每个通道占 1 字节 则总需要 4 个字节 用 int 类型刚好</span></span><br><span class="line">    <span class="type">int</span> color = <span class="number">0x00CC99FF</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 将颜色数据直接线性灌入LCD设备节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i =<span class="number">0</span>; i &lt; <span class="number">800</span> * <span class="number">480</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        write(file_descriptor, &amp;color, <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;lcd文件写入完毕\n&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 关闭文件</span></span><br><span class="line">    <span class="type">int</span> ret = close (file_descriptor);</span><br><span class="line">    <span class="keyword">if</span> (ret == <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;文件关闭失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;文件关闭成功\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>像上述代码这样，直接将数据通过设备节点 &#x2F;dev&#x2F;fb0 写入的话，这些数据会自动地从LCD映射内存的入口处（对应LCD屏幕的左上角）开始呈现，并且会以线性的字节流形式逐个字节往后填充，除非图像尺寸与显示器刚好完全一致，否则显示是失败的。</p><p>一般而言，图像的尺寸大小是随机的，因此更方便的做法是为LCD做<strong>内存映射</strong>，将屏幕的每一个像素点跟映射内存一一对应，而映射内存可以是二维数组，因此就可以非常方便地通过操作二维数组中的任意元素，来操作屏幕中的任意像素点了。这里的<strong>映射内存</strong>，有时被称为<strong>显存</strong>。</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md16.png" alt="md16"></p><p>如上图所示，将一块内存与LCD的像素一一对应：</p><ul><li>LCD上面显示的图像色彩，由其对应的内存的数据决定</li><li>映射内存的大小大于等于LCD的真实尺寸大小</li><li>映射内存的大小可以大于LCD的真实尺寸，有利于优化动态画面（视频）体验</li></ul><p>将原来代码修改如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3. 映射内存来进行LCD屏幕显示</span></span><br><span class="line"><span class="type">char</span> *p = mmap(<span class="literal">NULL</span>, <span class="number">800</span> * <span class="number">480</span> * <span class="number">4</span>, PROT_WRITE | PROT_READ, MAP_SHARED, file_descriptor, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">    perror(<span class="string">&quot;mmap error&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">800</span> * <span class="number">480</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// memcpy(p + i * 4, &amp;color, sizeof(int));</span></span><br><span class="line">    *(p + i) = color;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;lcd文件写入完毕\n&quot;</span>);</span><br><span class="line">munmap(p, <span class="number">800</span> * <span class="number">480</span> * <span class="number">4</span>);   <span class="comment">// 解除映射</span></span><br></pre></td></tr></table></figure><h3 id="2023-5-12"><a href="#2023-5-12" class="headerlink" title="2023.5.12"></a>2023.5.12</h3><p><strong>实战项目：</strong></p><p>要求：使用C语言代码编写菜单选项并实现其对应的功能<br>例：</p><p>——–欢迎使用…操作系统——-（使用switch语句）<br>1.德国国旗<br>2.法国国旗<br>3.瑞士国旗<br>4.日本国旗(公式:(x-x0)<em>(x-x0) + (y-y0)</em>(y-y0) &#x3D; r*r)<br>5.土耳其国旗（星星可以不用显示，选做加分）<br>6.各国国旗幻灯片形式播放（1s）<br>7.退出（break&#x2F;return）</p><h3 id="2023-5-13"><a href="#2023-5-13" class="headerlink" title="2023.5.13"></a>2023.5.13</h3><p>图片深度，一般有8bit、16bit、24bit 和 32bit等。</p><p>8bit：<br>$$<br>2^8 &#x3D; 2^2(B)*2^3(G)*2^3(R)&#x3D;256<br>$$<br>取值范围：0~255，总共可显示 256 种颜色。</p><p>16bit：<br>$$<br>2^{16} &#x3D; 2^5(B)*2^6(G)*2^5(R)&#x3D;65536<br>$$<br>24bit：<br>$$<br>2^{24} &#x3D; 2^8(B)*2^8(G)*2^8(R)&#x3D;16777215<br>$$<br>32bit：Alpha透明度 + 24 bit，ARGB。</p><p>为什么不使用常见的 jpg文件呢，因为 jpg文件为了便于能在网络上传播，经过了压缩处理，直接读取数据的话是<strong>读不到</strong>颜色数据的，需要经过<strong>解码</strong>才可以读出颜色数据；而 BMP文件是微软公司推出的一种图片数据格式，这种文件<strong>未经过压缩处理</strong>，读取颜色数据的时候<strong>无需进行解码</strong>，因此它的文件大小一般也很大。</p><p>BMP位图格式</p><p><strong>位图的文件头 Bitmap File Header (14 bytes)：</strong></p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md26.webp" alt="md26"></p><p>因此检查前两个字节即可得知此文件是否为 bmp文件，第一个字节为 0x42，第二个字节为 0x4D。</p><p><strong>位图信息数据头 DIB Header (54 bytes)：</strong></p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md27.webp" alt="md27"></p><p>bmp文件存储的数据为高位在前低位在后，这就是为什么前面第一个字节反而是 0x42，第二个字节为 0x4D，内容42 4D 对应了ASCII表的 ”BM“两个字母。</p><p>如一张 10 * 10的bmp图像</p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md28.webp" alt="md28"></p><p>在文件中数据顺序如下：另外 <strong>bmp存储颜色数据为 BGR 顺序。</strong>如下列红色画出 0000 ff表示的是红色。 </p><p><img src="/2023/05/19/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%AE%9E%E4%B9%A0/md29.webp" alt="md29"></p><p><strong>因此在读取 bmp文件的 颜色数据后需要将 BGR通道转为 ARGB通道显示在 lcd屏幕(32bit)；若为 24bit的 lcd屏幕，则转为 RGB通道即可；另外由于 bmp文件数据是高位在前低位在后，直接读取转换显示完图像是倒置的，需要将颜色数据从尾开始读取才可正常显示。</strong></p><h3 id="2023-5-15"><a href="#2023-5-15" class="headerlink" title="2023.5.15"></a>2023.5.15</h3><p><strong>使用U盘为开发板传输文件：</strong></p><p>如果 U盘是 <strong>fat32</strong>文件系统格式的，U盘可以直接挂载(mount)到到开发板。</p><ul><li>在开发板系统中进入中 <strong>&#x2F;mnt&#x2F;udisk</strong> 可看到插入U盘的信息；</li></ul><p>如果 U盘是 <strong>NTFS</strong>格式的，系统不会自动完成挂载，可以通过<strong>手动挂载</strong>，将 U盘挂载到 <strong>&#x2F;mnt&#x2F;udisk&#x2F;</strong> 目录下，然后通过该目录找到U盘。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入命令：</span><br><span class="line">mount -t ntfs /dev/sda1 /mnt/udisk</span><br></pre></td></tr></table></figure><h3 id="2023-5-16"><a href="#2023-5-16" class="headerlink" title="2023.5.16"></a>2023.5.16</h3><p><strong>播放音乐和视频</strong></p><p>音频或视频都通过某一个规则进行压缩和解码，我们的程序可以通过调用播放器来实现压缩和解码的过程，我们的程序主要用于控制播放、暂停、快进、快退等的一些操作即可。<br>开发板中默认有一个播放器 <strong>madplay</strong> 但是它<strong>只能用于播放音频文件MP3</strong>，不可以播放视频文件。因此可以从外部移植一个 mplayer 到开发板中，<strong>mplayer 则可以进行播放音频、视频文件</strong><br>1.检查开发板中是否已经存在播放器 ( &#x2F;bin&#x2F; &#x2F;usr&#x2F;bin&#x2F;) which madplay &#x2F; find -name madplaya如果不存在则手动移植 (复制)进去下载到mplayer程序文件到开发板后需要给它赋予可执行权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 111 mplayer</span><br><span class="line">mplayer xxx.avimplayer 文件名可以是视频文件，也可以是音频文件</span><br></pre></td></tr></table></figure><p>在虚拟机里面输入命令 kill -l 可以查看当前系统可以用的信号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ kill -l </span><br><span class="line"> 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP</span><br><span class="line"> 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1</span><br><span class="line">11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM</span><br><span class="line">16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP</span><br><span class="line">21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ</span><br><span class="line">26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR</span><br><span class="line">31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3</span><br><span class="line">38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8</span><br><span class="line">43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13</span><br><span class="line">48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12</span><br><span class="line">53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7</span><br><span class="line">58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2</span><br><span class="line">31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3</span><br><span class="line">38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8</span><br><span class="line">43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13</span><br><span class="line">48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12</span><br><span class="line">53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7</span><br><span class="line">58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2</span><br><span class="line">63) SIGRTMAX-1  64) SIGRTMAX</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> 9) SIGKILL    杀死某一个进程</span><br><span class="line">18) SIGCONT     给某一个进程发送继续运行的信号</span><br><span class="line">19) SIGSTOP   给某一个进程发送暂停运行的信号</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">注意:两个不同的播放器</span><br><span class="line"></span><br><span class="line">killall -9 mplayer  // 给当前系统中所有进程名为 mplayer 的进程发送 9号信号 （杀死）</span><br><span class="line">system(&quot;killall  -19 mplayer&quot;);  // 暂停播放</span><br><span class="line">system(&quot;killall  -18 mplayer&quot;);  // 继续播放</span><br><span class="line">system(&quot;killall  -9 mplayer&quot;);  // 结束播放器</span><br><span class="line"></span><br><span class="line">killall -9 madplay  // 给当前系统中所有进程名为 madplay 的进程发送 9号信号 （杀死）</span><br><span class="line">system(&quot;killall  -19 madplay&quot;);  // 暂停播放</span><br><span class="line">system(&quot;killall  -18 madplay&quot;);  // 继续播放</span><br><span class="line">system(&quot;killall  -9 madplay&quot;);  // 结束播放器</span><br></pre></td></tr></table></figure><p>视频：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">void send_cmd(int fifo_fd,char *cmd)  //发送指令</span><br><span class="line">&#123;</span><br><span class="line">//写入管道文件</span><br><span class="line">write(fifo_fd, cmd, strlen(cmd));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//mplayer初始化</span><br><span class="line">//判断是否存在管道文件，不存在才创建</span><br><span class="line">if(access(&quot;/fifo&quot;,F_OK))  //默认管道文件创建在根目录，F_OK判断是否存在</span><br><span class="line">&#123;</span><br><span class="line">//条件成立，不存在管道文件</span><br><span class="line">mkfifo(&quot;/fifo&quot;,777);  //创建管道文件</span><br><span class="line">&#125;</span><br><span class="line">//打开管道文件</span><br><span class="line">int fifo_fd = open(&quot;/fifo&quot;,O_RDWR); </span><br><span class="line">if(fifo_fd == -1)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;管道文件打开失败\n&quot;);</span><br><span class="line">return -1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 一开始的视频播放</span><br><span class="line">system(&quot;mplayer -slave -quiet -geometry 0:0 -zoom -x 800 -y 400./Test_bmp/Test1.avi&quot;);   </span><br><span class="line">//发送暂停(广义的暂停，即若视频正在播放则暂停播放；若视频暂停播放则开始播放)指令</span><br><span class="line">send_cmd(fifo_fd,&quot;pause\n&quot;); </span><br><span class="line">//音量＋</span><br><span class="line">send_cmd(fifo_fd,&quot;volume -10\n&quot;);</span><br><span class="line">//音量－</span><br><span class="line">send_cmd(fifo_fd,&quot;volume +10\n&quot;);</span><br><span class="line">//kill　mplayer播放器</span><br><span class="line">system(&quot;killall  -9 mplayer&quot;);</span><br></pre></td></tr></table></figure><h3 id="2023-5-17-2023-5-18"><a href="#2023-5-17-2023-5-18" class="headerlink" title="2023.5.17-2023.5.18"></a>2023.5.17-2023.5.18</h3><p>项目整合模块</p><p><strong>主界面：包含四个模块</strong></p><ul><li><p>电子相册V3</p></li><li><p>音乐播放器</p></li><li><p>视频播放器</p></li><li><p>游戏</p></li></ul><p>选择第一个模块可以进入电子相册界面。进入程序的界面需要点击两次右上角才可退回主界面</p><p><strong>电子相册界面包括：</strong></p><ul><li>手动播放：水平滑动和垂直滑动切换图片</li><li>循环播放：循环 2 次，循环后自动返回到电子相册界面；时间原因还未设置手动退出选项。</li></ul><p><strong>音乐播放器界面包括：</strong></p><ul><li>播放音乐</li><li>暂停音乐</li><li>上一首音乐</li><li>下一首音乐</li></ul><p><strong>视频播放器界面包括：</strong></p><ul><li>开始</li><li>暂停</li><li>继续</li><li>调高音量</li><li>调低音量</li></ul><p><strong>游戏界面 ：雷霆战机</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>项目分模块写的时候需要考虑项目的耦合性，尽量封装成一个函数便于他人可直接调用；</li><li>编写代码时尽量少用全局变量，过多使用全局变量一方面会增加程序运行的内存，也会降低代码的耦合性，加大项目整合模块的难度；</li><li>若声明了全局变量，切忌在函数中再次声明定义同个变量，否则会导致不必要的麻烦；</li><li>目前的编程能力太弱了，有待提高，使用的代码都是很低级的并且重复性很高，后续应当通过许多编程小项目提高自己的编程能力。</li></ul><blockquote><p><a href="https://www.cnblogs.com/wzk-0000/p/11083008.html">sudo -i和sudo -s - 乌瑟尔 - 博客园 (cnblogs.com)</a></p><p><a href="https://blog.csdn.net/vincent040/article/details/116301614">(49条消息) Linux-FrameBuffer双缓冲机制显示图像_fb双缓冲_干燥剂007860的博客-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/25119530">浅谈图像格式 .bmp - 知乎 (zhihu.com)</a></p><p><a href="https://blog.csdn.net/m0_57266121/article/details/118979056">https://blog.csdn.net/m0_57266121/article/details/118979056</a></p><p><a href="https://blog.csdn.net/weixin_50722786/article/details/126572958">(50条消息) 利用GEC6818屏幕 显示一张bmp图片_read(bmp_fd,&amp;bpp,2);_三目条件的博客-CSDN博客</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;嵌入式实践实习知识&quot;&gt;&lt;a href=&quot;#嵌入式实践实习知识&quot; class=&quot;headerlink&quot; title=&quot;嵌入式实践实习知识&quot;&gt;&lt;/a&gt;嵌入式实践实习知识&lt;/h2&gt;&lt;p&gt;大二下时长一周半多半周的嵌入式实习，由粤嵌的工程师教授知识。&lt;/p&gt;
&lt;p&gt;环境及工</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://example.com/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>Ubuntu共享文件夹问题</title>
    <link href="http://example.com/2023/05/10/Ubuntu%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2023/05/10/Ubuntu%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%E9%97%AE%E9%A2%98/</id>
    <published>2023-05-10T04:12:18.000Z</published>
    <updated>2023-08-07T09:58:56.010Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Ubuntu 18.04 每次重启后共享文件夹未显示问题。</strong></p><p>虽然虚拟机设置了总是启用共享文件夹，但是每次重启虚拟机之后还是未显示共享文件夹。</p><p><img src="/2023/05/10/Ubuntu%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%E9%97%AE%E9%A2%98/md11.png" alt="md11"></p><p>通过以下命令查看共享文件夹是否存在。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vmware-hgfsclient</span><br></pre></td></tr></table></figure><p><img src="/2023/05/10/Ubuntu%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%E9%97%AE%E9%A2%98/md12.png" alt="md12"></p><p>这边查询到共享文件夹是存在的，在 &#x2F;mnt&#x2F;hgfs 下进行 ls 查看目录时，共享文件夹并没显示。</p><p><img src="/2023/05/10/Ubuntu%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%E9%97%AE%E9%A2%98/md13.png" alt="md13"></p><p>使用以下命令可以得到解决，但是重启虚拟机之后仍然会出现找不到共享文件夹的问题。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vmhgfs-fuse .host:/ /mnt/hgfs -o nonempty -o allow_other</span><br></pre></td></tr></table></figure><p>显然这种方法是不优的，因此采用下述方法，把这个命令放在 &#x2F;etc&#x2F;rc.local文件夹下，即可每次开机自动执行。</p><p>普通用户下执行命令打开 rc.local 文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/rc.local</span><br></pre></td></tr></table></figure><p>写入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh -e</span><br><span class="line"></span><br><span class="line">sudo vmhgfs-fuse .host:/ /mnt/hgfs -o nonempty -o allow_other</span><br></pre></td></tr></table></figure><p>在 &#x2F;etc 目录下输入 cat rc.local 查看是否添加成功。</p><p><img src="/2023/05/10/Ubuntu%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%E9%97%AE%E9%A2%98/image-20230510123036146.png" alt="image-20230510123036146"></p><p>在 &#x2F;etc 目录下输入 ls -l 可知 rc.local 的权限不可执行，因此需要为其添加权限。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod +x rc.local</span><br></pre></td></tr></table></figure><p>最后重启虚拟机即可。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Ubuntu 18.04 每次重启后共享文件夹未显示问题。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;虽然虚拟机设置了总是启用共享文件夹，但是每次重启虚拟机之后还是未显示共享文件夹。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/05/10/Ubuntu%E5%85%</summary>
      
    
    
    
    <category term="Linux" scheme="http://example.com/categories/Linux/"/>
    
    
    <category term="虚拟机" scheme="http://example.com/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    <category term="Ubuntu" scheme="http://example.com/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>硬件通讯协议</title>
    <link href="http://example.com/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/"/>
    <id>http://example.com/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/</id>
    <published>2023-05-08T13:33:49.000Z</published>
    <updated>2023-08-07T09:51:46.928Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一些基础概念"><a href="#一些基础概念" class="headerlink" title="一些基础概念"></a>一些基础概念</h2><h3 id="串行通信协议"><a href="#串行通信协议" class="headerlink" title="串行通信协议"></a>串行通信协议</h3><p><strong>同步通信(asynchronous data communication)<strong>：以</strong>数据块</strong>为单位传输，收发方<strong>必须</strong>使用同一时钟源。</p><p><strong>异步通信(synchronous data communication)<strong>：以</strong>字符</strong>为单位传输，两个字符之间传输的时间间隔不固定的，但同个字符内部的时间间隔是固定的，收发方<strong>无需</strong>使用同一时钟源，只要时钟信号的<strong>频率相同</strong>即可。</p><p><strong>异步通信</strong>通过传送字符内的<strong>起始位</strong>来进行同步，而<strong>同步通信</strong>采用<strong>共用外部时钟</strong>来进行同步。</p><p>通俗点来说：同步通信就是舔狗发微信找女神，对方一直不回复，但舔狗一直在那等待回复；异步通信就是一个比较聪明点的舔狗发微信找女神，对方一直不回复，但舔狗不在那一直等待回复，选择了干其他事情。</p><h3 id="数据传送方式"><a href="#数据传送方式" class="headerlink" title="数据传送方式"></a>数据传送方式</h3><p>单工：只有一个固定方向进行传送数据。</p><p>半双工：双方都可以进行传送数据，但不能同时传送和接收数据，即只存在一方传送，一方接收。</p><p>全双工：双方都可以进行发送数据，并且可以同时传送和接收数据。</p><h3 id="常见电平标准"><a href="#常见电平标准" class="headerlink" title="常见电平标准"></a>常见电平标准</h3><p>TTL 电平：全双工，1：2.4V~5V，0：0.</p><table><thead><tr><th align="center">电平类型</th><th align="center">通信方式</th><th>逻辑1</th><th>逻辑0</th></tr></thead><tbody><tr><td align="center">TTL 电平</td><td align="center">全双工</td><td>2.4V~5V</td><td>0V~0.5V</td></tr><tr><td align="center">COMS 电平</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">RS232</td><td align="center">全双工</td><td>-15V~-5V</td><td>+3V~+15V</td></tr><tr><td align="center">RS485</td><td align="center">半双工</td><td>+2V~+6V</td><td>-6V~-2V</td></tr></tbody></table><h3 id="串口参数"><a href="#串口参数" class="headerlink" title="串口参数"></a>串口参数</h3><ul><li>波特率：串口通信的速率 单位一般为 bit&#x2F;s，一秒传送多少位，波特率的倒数就是传送 1 位的时间。</li><li>起始位：标志一个数据帧的开始，固定为低电平。</li><li>数据位：数据帧的有效载荷，1 为高电平，0 为低电平，<strong>低位先行</strong>即一组数据是低位先入。</li><li>检验位：用于数据验证，根据数据位计算得来。</li><li>停止位：用于数据帧间隔，固定为高电平</li></ul><p>TX 引脚与 GND 进行比较输出定时翻转的高低电平，RX 引脚定时读取引脚的高低电平，每个字节的数据加上起始位、停止位、可选的检验位封装位数据帧，依次输出在 TX 引脚，另一端 RX 引脚依次接收。</p><p><strong>硬件流控制</strong>：多接了根线连接发送端和接收端，只有当接收端准备好了告诉发送端，发送端才开始发送数据。<strong>防止发送端数据太快导致接收端数据丢失或被覆盖。</strong></p><h2 id="常见的硬件通讯协议"><a href="#常见的硬件通讯协议" class="headerlink" title="常见的硬件通讯协议"></a>常见的硬件通讯协议</h2><h3 id="UART"><a href="#UART" class="headerlink" title="UART"></a>UART</h3><p>UART——通用异步收发传输器，工作原理是将传输数据的每个字符一位接一位地传输。只要 2 根传输线就可以实现双向通信，一根线发送数据的同时用另一根线接收数据。</p><p>由于 UART 是异步通信，因此对于两个使用 UART串口通信的端口，这些参数必须匹配，否则通信出错。</p><p><strong>通信数据格式</strong></p><ul><li><p>起始位：表示数据传输的开始，电平逻辑为“0” ，位数为1位。</p></li><li><p>数据位：可以是5~8位的数据，先发低位，再发高位，一般取值为8，因为一个ASCII 字符值为8位。</p></li><li><p>奇偶校验位：用于接收方对接收到的数据进行校验，“1”的位数为偶数(偶校验) 或奇数(奇校验)，以此来校验数据传送的正确性，使用时不需要此位也可以。</p></li><li><p>停止位：表示一帧数据的结束，电平逻辑为“1”，位数可以是1&#x2F;1.5&#x2F;2位。</p></li><li><p>波特率：串口通信时的速率，它用单位时间内传输的二进制代码的有效位(bit) 数来表示，其单位为每秒比特数bit&#x2F;s(bps)。常见的波特率值有4800、9600、115200 等，数值越大数据传输的越快，波特率为115200 表示每秒钟传输115200 位数据。</p></li></ul><p>连接方式为 TX——RX，RX——TX，GND——GND。</p><ul><li>UART只是对信号的时序进行了定义，而未定义接口的电气特性；</li><li>UART通信时一般直接使用处理器使用的电平，即TTL电平，但<strong>不同的处理器使用的电平存在差异</strong>，所以不同的处理器使用UART通信时<strong>一般不能直接相连</strong>；</li><li>UART没有规定不同器件连接时连接器的标准，所以不同器件之间通过UART通信时连接不方便。</li><li>UART一般直接使用 TTL信号来表示 0 和 1，但 TTL信号的抗干扰能力较差，数据在传输过程中很容易出错。</li><li>由于TTL信号的抗干扰能力较差，所以其通信距离很短，一般只能用于一个电路板上的两个不同芯片之间的通信。</li></ul><h3 id="USART"><a href="#USART" class="headerlink" title="USART"></a>USART</h3><p>通用同步异步收发器（Universal Synchronous Asynchronous Receiver Transmitter）</p><p>内容跟 UART 类似，不过 USART 比 UART 多了另外一种通信方式——异步通信，即 USART 既可以异步通信也可以同步通信，具体设置方式参考手册。</p><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md20.png" alt="md20"></p><p><strong>TX</strong>：发送数据<strong>输出</strong>引脚。<br><strong>RX</strong>：接收数据<strong>输入</strong>引脚。<br><strong>SW_RX</strong>：数据接收引脚，只用于单线和智能卡模式，属于内部引脚，没有具体外部引脚。<br><strong>nRTS</strong>： 请求以发送(Request To Send)，<strong>n 表示低电平有效</strong>。如果使能 RTS 流控制，当USART 接收器准备好接收新数据时就会将 nRTS 变成低电平；当接收寄存器已满时，nRTS 将被设置为高电平。该引脚只适用于<strong>硬件流控制</strong>。<br><strong>nCTS</strong>： 清除以发送(Clear To Send)，<strong>n 表示低电平有效</strong>。如果使能 CTS 流控制，发送器在发送下一帧数据之前会检测 nCTS 引脚，如果为低电平，表示可以发送数据，如果为高电平则在发送完当前数据帧之后停止发送。该引脚只适用于<strong>硬件流控制</strong>。<br><strong>SCLK</strong>： 发送器时钟输出引脚。</p><p><strong>编程时常用的标志位</strong></p><ul><li>RE：接收使能</li><li>RXNE：读数据寄存器非空</li><li>RXNEIE：发送完成中断使能</li></ul><p>USART 支持使用 DMA，可实现高速数据通信，USART 在 STM32 常用于<strong>打印</strong>程序信息，一般在硬件设计时都会预留一个 USART 通信接口连接电脑，用于在调试程序是可以把一些调试信息<strong>打印</strong>在电脑端的串口调试助手工具上，从而了解程序运行是否正确、如果出错具体哪里出错等等。</p><h3 id="IIC"><a href="#IIC" class="headerlink" title="IIC"></a>IIC</h3><p><strong>IIC（Inter-Integrated Circuit集成电路总线）</strong>是一种串行通信总线，使用多主从架构，利用该总线可实现多主机系统所需的裁决和高低速设备同步等功能。</p><ul><li>IIC 总线是一种<strong>串行、半双工总线</strong>，<strong>同步通信</strong>、主要用于近距离、低速的芯片之间的通信。</li><li>IIC 串行总线一般有<strong>两根信号线</strong>，一根是双向的<strong>数据线 SDA</strong> 收发数据，另一根是<strong>时钟线 SCL</strong> 双方时钟同步。所有接到IIC总线设备上的串行数据 SDA 都接到总线的 SDA 上，各设备的时钟线 SCL 接到总线的 SCL 上。</li><li>IIC 是真正的多主机总线，（IIC可以在通讯过程中，改变主机）。如果两个或更多的主机同时请求总线，可以通过<strong>冲突检测</strong>和<strong>仲裁</strong>防止总线数据被破坏。</li><li>多个 IIC 器件可以并联在 IIC 总线上，每个器件有特定的地址，分时共享 IIC 总线<strong>。连接到 IIC 总线上的设备既可以用作主设备，也可以用作从设备</strong>。主设备负责控制通信，通过对数据传输进行初始化&#x2F;终止化，来发送数据并产生所需的同步时钟脉冲。从设备则是等待来自主设备的命令，并响应命令接收。主设备和从设备都可以作为发送设备或接收设备。无论主设备是作为发送设备还是接收设备，<strong>同步时钟信号都只能由主设备产生</strong>。</li><li>串行的 8 位双向数据传输位速率在标准模式下可达 100kbit&#x2F;s，快速模式下可达 400kbit&#x2F;s ，高速模式下可达 3.4Mbit&#x2F;s。</li></ul><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md19.png" alt="md19"></p><p>SCL 为高时，SDA 由高电平——&gt;低电平，表示起始位。</p><p>SCL 为高时，SDA 由低电平——&gt;高电平，表示停止位。</p><p>SCL 为高时，SDA 始终为高电平，表示逻辑 1。</p><p>SCL 为高时，SDA 始终为低电平，表示逻辑 0。</p><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md17.png" alt="md17"></p><p>数据帧中，0 表示写数据，1 表示读数据；应答信号中，0 表示数据被正确接收，1 表示从机正忙，接收错误。</p><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md18.png" alt="md18"></p><p>IIC 中由于是多主机进行通信，各主机互相抢占总线，多主机会产生总线裁决问题。当多个主机同时想占用总线时，企图启动总线传输数据，就叫做<strong>总线竞争</strong>。I2C通过<strong>总线仲裁</strong>，以决定哪台主机控制总线。在多主机中寻址需要在数据帧中添加设备地址，这个设备地址为 7 位，支持最多 255 台主机通信。</p><p>在起始信号后必须传送一个从机的地址(7 位)，第 8 位是数据的传送方向位(R&#x2F;T)，用“0”表示主机发送数据(T)，“1”表示主机接收数据(R)。</p><p><strong>优点：</strong></p><ul><li>简单的两线串行 IIC 总线，节省 PCB 布板走线空间。</li><li>完全集成的 IIC总线协议消除了地址解码器。</li><li>标准支持广泛，大量无铅封装 I2C 总线兼容集成芯片进一步降低了空间需求。</li><li>控制方式简单、器件封装形式小、通信速率较高。</li></ul><p><strong>缺点：</strong></p><ul><li>数据传输速率较慢；</li><li>只适用短距离传输。</li></ul><h3 id="SPI"><a href="#SPI" class="headerlink" title="SPI"></a>SPI</h3><p>SPI是串行外设接口（Serial Peripheral Interface）的缩写，是一种高速的，全双工，同步的通信总线。它以主从方式工作，这种模式通常有一个主设备和一个或多个从设备，需要至少4根线，事实上3根也可以（单向传输时）。</p><p>SPI 是一个环形总线结构，由<strong>MOSI、MISO、SCLK、SS 四根线</strong>构成，其时序其实很简单，主要是在SCLK 的控制下，两个双向移位寄存器进行数据交换。</p><ul><li>**MISO (Master Input Slave Output)**：主设备数据输入，从设备数据输出；</li><li>**MOSI (Master Output Slave Input)**：主设备数据输出，从设备数据输入；</li><li>**SCLK (Serial Clock)**：时钟信号，由主设备产生；</li><li>**SS (Slave Selection)**：外围设备片选信号线，用来选择哪个设备工作。</li></ul><p>连接图大致如下：</p><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md21.png" alt="md21"></p><p>操作码 01：写数据；10：读数据。在多主机中寻址需要在数据帧中添加设备地址，这个设备地址为 7 位，支持最多 255 台主机通信。</p><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md22.png" alt="md22"></p><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md23.png" alt="md23"></p><p><img src="/2023/05/08/%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE/md24.png" alt="md24"></p><p>在 SPI 操作中，有两项比较重要的设置，就是时钟极性（**CPOL(Clock Polarity)<strong>或 UCCKPL）和时钟相位（</strong>CPHA(Clock Phase)**或 UCCKPH）。</p><p>时钟极性设置时钟空闲时的电平。当时钟极性为 <strong>0</strong> 时（CPOL&#x3D;0），SCK信号线在空闲时为<strong>低电平</strong>；当时钟极性为 <strong>1</strong> 时（CPOL&#x3D;1），SCK信号线在空闲时为<strong>高电平</strong>。</p><p>时钟相位设置读取数据和发送数据的时钟沿，用来决定何时进行信号采样。</p><table><thead><tr><th align="center">SPI 模式</th><th align="center">CPOL</th><th align="center">CPHA</th><th align="center">空闲状态下的时钟极性</th><th align="center">用于采样和移位数据的时钟相位</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">0</td><td align="center">0</td><td align="center">逻辑低电平</td><td align="center">数据在上升沿采样，在下降沿发送</td></tr><tr><td align="center">1</td><td align="center">0</td><td align="center">1</td><td align="center">逻辑低电平</td><td align="center">数据在下降沿采样，在上升沿发送</td></tr><tr><td align="center">2</td><td align="center">1</td><td align="center">1</td><td align="center">逻辑高电平</td><td align="center">数据在下降沿采样，在上升沿发送</td></tr><tr><td align="center">3</td><td align="center">1</td><td align="center">0</td><td align="center">逻辑高电平</td><td align="center">数据在上升沿采样，在下降沿发送</td></tr></tbody></table><p><strong>SPI 接口主要应用</strong>在 EEPROM，FLASH，实时时钟，AD转换器，还有数字信号处理器和数字信号解码器之间。</p><p><strong>优点：</strong></p><ul><li>支持全双工，推挽(push-pull)的驱动性能相比开漏(open-drain)信号完整性更好；</li><li>硬件连接简单，且支持高速（100MHz以上）；</li><li>协议支持<strong>数据字长不限于 8bits</strong>，可根据应用特点灵活选择消息字长。</li><li>在点对点的通信中，SPI接口进行片选从机，<strong>不</strong>需要进行寻址操作，且为全双工通信，显得简单高效。</li></ul><p><strong>缺点：</strong></p><ul><li>相比IIC多两根线，没有寻址机制，只能靠片选选择不同设备；</li><li>没有指定的流控制，没有应答机制（ACK）确认是否接收到数据，主设备对于发送成功与否不得而知；</li><li>典型应用只支持单主控，只有一个主机；</li><li>在多个从器件的系统中，每个从器件需要独立的使能信号，硬件上比 I2C系统要稍微复杂一些。</li><li>SPI仅适用于短距离传输。</li></ul><h3 id="CAN"><a href="#CAN" class="headerlink" title="CAN"></a>CAN</h3><h3 id="USB"><a href="#USB" class="headerlink" title="USB"></a>USB</h3><h3 id="Type-C"><a href="#Type-C" class="headerlink" title="Type-C"></a>Type-C</h3><blockquote><p><a href="https://blog.csdn.net/m0_46582811/article/details/124039693">(49条消息) 常用的嵌入式硬件通信接口协议（UART、IIC、SPI、RS-232、RS-485、RS-422、CAN、USB、IRDA）（二）_嵌入式硬件接口_木木9026的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/m0_46582811/article/details/124039693">(49条消息) 常用的嵌入式硬件通信接口协议（UART、IIC、SPI、RS-232、RS-485、RS-422、CAN、USB、IRDA）（二）_嵌入式硬件接口_木木9026的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/m0_46582811/article/details/124123349?spm=1001.2014.3001.5502">(49条消息) 常用的嵌入式硬件通信接口协议（UART、IIC、SPI、RS-232、RS-485、RS-422、CAN、USB、IRDA）（三）_硬件协议接口对接_木木9026的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/shaguahaha/article/details/70766665">(49条消息) IIC详解，包括原理、过程，最后一步步教你实现IIC_shaguahaha的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/qq_54747686/article/details/119237161">(49条消息) STM32 USART通信协议详细讲解—小白入门_usart基础知识_阿乔不想编程的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/qq_43489868/article/details/124000513?ops_request_misc=%7B%22request_id%22:%22168355344016800188566377%22,%22scm%22:%2220140713.130102334.pc_all.%22%7D&request_id=168355344016800188566377&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-1-124000513-null-null.142%5Ev86%5Einsert_down1,239%5Ev2%5Einsert_chatgpt&utm_term=%E7%A1%AC%E4%BB%B6%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE">(49条消息) 常用硬件通信协议_硬件协议_爱吃饭的王的博客-CSDN博客</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一些基础概念&quot;&gt;&lt;a href=&quot;#一些基础概念&quot; class=&quot;headerlink&quot; title=&quot;一些基础概念&quot;&gt;&lt;/a&gt;一些基础概念&lt;/h2&gt;&lt;h3 id=&quot;串行通信协议&quot;&gt;&lt;a href=&quot;#串行通信协议&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://example.com/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
    <category term="嵌入式" scheme="http://example.com/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降法</title>
    <link href="http://example.com/2023/04/25/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    <id>http://example.com/2023/04/25/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</id>
    <published>2023-04-25T09:09:10.000Z</published>
    <updated>2023-08-07T09:53:27.480Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/pdf/1412.6980v8.pdf">1412.6980v8.pdf (arxiv.org)</a></p><p><a href="https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">duchi11a.dvi (jmlr.org)</a></p><p><a href="http://www.cs.toronto.edu/~tijmen/csc321/lecture_notes.shtml">CSC321 Winter 2014: lecture notes (toronto.edu)</a></p><p>[<a href="https://arxiv.org/abs/1212.5701">1212.5701] ADADELTA: An Adaptive Learning Rate Method (arxiv.org)</a></p><p><a href="http://cs229.stanford.edu/proj2015/054_report.pdf">cs229.stanford.edu&#x2F;proj2015&#x2F;054_report.pdf</a></p><p>[<a href="https://arxiv.org/abs/1212.5701">1212.5701] ADADELTA: An Adaptive Learning Rate Method (arxiv.org)</a></p><p><a href="http://proceedings.mlr.press/v49/lee16.pdf">lee16.pdf (mlr.press)</a><br><a href="https://arxiv.org/pdf/1609.04747.pdf">1609.04747.pdf (arxiv.org)</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1412.6980v8.pdf&quot;&gt;1412.6980v8.pdf (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jmlr.org/papers/</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>正则化方法</title>
    <link href="http://example.com/2023/04/25/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2023/04/25/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/</id>
    <published>2023-04-25T09:08:36.000Z</published>
    <updated>2023-08-07T09:52:23.355Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是正则化（Regularization）"><a href="#什么是正则化（Regularization）" class="headerlink" title="什么是正则化（Regularization）"></a>什么是正则化（Regularization）</h2><p>深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于<strong>避免过拟合或减少你的网络误差</strong>。</p><p>规范化中并没有对偏置项进行规范化，因为即使对偏置进行规范化操作也并不会对结果改变太多，所以，在某种程度上，对不对偏置进行规范化其实就是一种习惯了。然而，需要注意的是，有一个大的偏置并不会像大的权重那样会让神经元对输入太过敏感。所以我们不需要对大的偏置所带来的学习训练数据的噪声太过担心。同时，允许大的偏置能够让网络更加灵活。因为大的偏置让神经元更加容易饱和，这有时候是我们所要达到的效果。所以，我们通常不会对偏置进行规范化。</p><h2 id="正则化方法"><a href="#正则化方法" class="headerlink" title="正则化方法"></a>正则化方法</h2><h3 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h3><p>L1 规范化是在未规范化的代价函数上加上一个权重绝对值的和：<br>$$<br>Cost &#x3D; Loss + \frac{\lambda}{n}\sum_w \vert \vert w \vert \vert_1<br>$$<br>对 $w$ 求偏导：<br>$$<br>\frac </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是正则化（Regularization）&quot;&gt;&lt;a href=&quot;#什么是正则化（Regularization）&quot; class=&quot;headerlink&quot; title=&quot;什么是正则化（Regularization）&quot;&gt;&lt;/a&gt;什么是正则化（Regularizatio</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>权重初始化</title>
    <link href="http://example.com/2023/04/25/%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
    <id>http://example.com/2023/04/25/%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96/</id>
    <published>2023-04-25T09:07:22.000Z</published>
    <updated>2023-08-07T09:53:02.973Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么要初始化权重"><a href="#为什么要初始化权重" class="headerlink" title="为什么要初始化权重"></a>为什么要初始化权重</h2><p>训练神经网络需要指定权重的初始值，而一个好的初始化方法将有助于网络学习。</p><p>好的初始化可以加快梯度下降、模型收敛；减小梯度下降收敛过程中训练和泛化出现误差的几率；</p><p>在一个多层的神经网络的正向传播和反向传播中，可知经常会出现连乘的计算，假设激活函数为线性函数，则 $y &#x3D; W_n W_{n-1}···W_2W_1x$ ，当权重 W 小于 1 时，由于连乘可知结果很容易出现指数级减小；当权重 W 大于 1 时，由于连乘可知结果很容易出现指数级爆炸式增长；</p><p>梯度消失和梯度爆炸问题都是因为<strong>网络太深，网络权值更新不稳定造成的，本质上是因为梯度反向传播中的连乘效应。</strong></p><p>通过选择好的初始化权重一般可以有效减小这种问题的出现。</p><h2 id="初始化权重方法"><a href="#初始化权重方法" class="headerlink" title="初始化权重方法"></a>初始化权重方法</h2><h3 id="零初始化-不推荐"><a href="#零初始化-不推荐" class="headerlink" title="零初始化(不推荐)"></a>零初始化(不推荐)</h3><p>通常，将所有权重初始化为零会导致网络无法打破<strong>对称性</strong>。</p><p>当所有初始值相同时，例如将每个权重初始化为0，然后进行反向传播时，所有权重将具有相同的梯度，因此也将具有相同的更新。这就是所谓的<strong>对称性</strong>。这意味着所有节点都将学习相同的东西，而我们不希望这样做，因为我们希望网络学习不同种类的功能。</p><p>若权重通过随机初始化实现的，此后梯度将有所不同，并且每个节点将变得与其他节点更加不同，从而可以进行多种特征提取。这就是所谓的破坏对称性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_parameters_zeros</span>(<span class="params">layers_dims</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the size of each layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layers_dims[1], 1)</span></span><br><span class="line"><span class="string">                    ...</span></span><br><span class="line"><span class="string">                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])</span></span><br><span class="line"><span class="string">                    bL -- bias vector of shape (layers_dims[L], 1)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 零初始化</span></span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = <span class="built_in">len</span>(layers_dims)</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">&#x27;W&#x27;</span> + <span class="built_in">str</span>(l)] = np.zeros((layers_dims[l], layers_dims[l - <span class="number">1</span>]))</span><br><span class="line">        parameters[<span class="string">&#x27;b&#x27;</span> + <span class="built_in">str</span>(l)] = np.zeros((layers_dims[l], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="随机初始化-不推荐"><a href="#随机初始化-不推荐" class="headerlink" title="随机初始化(不推荐)"></a>随机初始化(不推荐)</h3><p>随机分布选择不当会导致网络优化陷入困境。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_parameters_random</span>(<span class="params">layers_dims</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the size of each layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layers_dims[1], 1)</span></span><br><span class="line"><span class="string">                    ...</span></span><br><span class="line"><span class="string">                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])</span></span><br><span class="line"><span class="string">                    bL -- bias vector of shape (layers_dims[L], 1)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 将权重初始化为较大的随机值 看结果会怎么样</span></span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = <span class="built_in">len</span>(layers_dims)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">&#x27;W&#x27;</span> + <span class="built_in">str</span>(l)] = np.random.randn(layers_dims[l], layers_dims[l - <span class="number">1</span>]) * <span class="number">10</span></span><br><span class="line">        parameters[<span class="string">&#x27;b&#x27;</span> + <span class="built_in">str</span>(l)] = np.zeros((layers_dims[l], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="Xavier初始化"><a href="#Xavier初始化" class="headerlink" title="Xavier初始化"></a>Xavier初始化</h3><p>早期的参数初始化普遍是将数据和参数normalize为高斯分布（均值0，方差1），但随着神经网络深度的增加，这个方法并不能解决梯度消失的问题。</p><blockquote><p>Xavier初始化的作者，Xavier Glorot，发现：激活值的方差是逐层递减的，这导致反向传播中的梯度也逐层递减。要解决梯度消失，<strong>就要避免激活值方差的衰减，即每一层输出的方差应该尽量相等。</strong></p></blockquote><p>Xavier初始化的基本思想是，若对于一层网络的 <strong>输出和输出可以保持正态分布且方差相近</strong>，这样就可以避免输出趋向于0，从而避免梯度消失情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_parameters_Xavier</span>(<span class="params">layers_dims</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the size of each layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layers_dims[1], 1)</span></span><br><span class="line"><span class="string">                    ...</span></span><br><span class="line"><span class="string">                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])</span></span><br><span class="line"><span class="string">                    bL -- bias vector of shape (layers_dims[L], 1)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># He初始化</span></span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = <span class="built_in">len</span>(layers_dims)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">&#x27;W&#x27;</span> + <span class="built_in">str</span>(l)] = np.random.randn(layers_dims[l], layers_dims[l - <span class="number">1</span>]) * np.sqrt(</span><br><span class="line">            <span class="number">2.</span>/ layers_dims[l - <span class="number">1</span>])</span><br><span class="line">        parameters[<span class="string">&#x27;b&#x27;</span> + <span class="built_in">str</span>(l)] = np.zeros((layers_dims[l], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="He初始化"><a href="#He初始化" class="headerlink" title="He初始化"></a>He初始化</h3><p>Xavier 在 tanh 中表现的很好，但在 Relu 激活函数中表现的很差，He是针对于Relu的初始化方法。</p><p>He 初始化和 xavier 一样都是为了防止梯度弥散而使用的初始化方式。He初始化的出现是因为xavier 存在一个不成立的假设, xavier 在推导中假设激活函数都是线性的，而在深度学习中常用的ReLu 等都是<strong>非线性</strong>的激活函数。</p><p> He 初始化本质上是高斯分布初始化，与上述高斯分布初始化有所不同，其是个满足均值为 0，方差为 2&#x2F;n 的高斯分布。</p><p>由于<strong>ReLU 函数</strong>让<strong>一半</strong>的Z值（负值）变为零，实际上移除了大约一半的方差。所以我们需要<strong>加倍权重的方差</strong>以补偿这一点。补偿的方法，只需要对 Xavier 初始化进行一项微小的调整——将权重的方差乘以2。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_parameters_he</span>(<span class="params">layers_dims</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    layer_dims -- python array (list) containing the size of each layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:</span></span><br><span class="line"><span class="string">                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])</span></span><br><span class="line"><span class="string">                    b1 -- bias vector of shape (layers_dims[1], 1)</span></span><br><span class="line"><span class="string">                    ...</span></span><br><span class="line"><span class="string">                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])</span></span><br><span class="line"><span class="string">                    bL -- bias vector of shape (layers_dims[L], 1)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># He初始化</span></span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = <span class="built_in">len</span>(layers_dims)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">&#x27;W&#x27;</span> + <span class="built_in">str</span>(l)] = np.random.randn(layers_dims[l], layers_dims[l - <span class="number">1</span>]) * np.sqrt(</span><br><span class="line">            <span class="number">2.</span>/ layers_dims[l - <span class="number">1</span>])</span><br><span class="line">        parameters[<span class="string">&#x27;b&#x27;</span> + <span class="built_in">str</span>(l)] = np.zeros((layers_dims[l], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://arxiv.org/pdf/1511.06422.pdf">1511.06422.pdf (arxiv.org)</a></p><p><a href="https://arxiv.org/pdf/1702.08591.pdf">1702.08591.pdf (arxiv.org)</a></p><p><a href="https://zhuanlan.zhihu.com/p/102708578">啃一啃神经网络——权重初始化 - 知乎 (zhihu.com)</a></p><p><a href="https://blog.csdn.net/VictoriaW/article/details/73166752">(47条消息) 深度学习之参数初始化（二）——Kaiming初始化_凯明初始化公式_Vic时代的博客-CSDN博客</a></p><p><a href="https://aistudio.csdn.net/62e38a2dcd38997446774b1e.html?spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-7-51338178-blog-107890916.235%5Ev32%5Epc_relevant_default_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-7-51338178-blog-107890916.235%5Ev32%5Epc_relevant_default_base3&utm_relevant_index=13">深度学习——Xavier初始化方法_shuzfan-DevPress官方社区 (csdn.net)</a></p><p><a href="https://www.cnblogs.com/shixiangwan/p/7566994.html">Deep Learning基础–参数优化方法 - 蓝鲸王子 - 博客园 (cnblogs.com)</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;为什么要初始化权重&quot;&gt;&lt;a href=&quot;#为什么要初始化权重&quot; class=&quot;headerlink&quot; title=&quot;为什么要初始化权重&quot;&gt;&lt;/a&gt;为什么要初始化权重&lt;/h2&gt;&lt;p&gt;训练神经网络需要指定权重的初始值，而一个好的初始化方法将有助于网络学习。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>损失函数</title>
    <link href="http://example.com/2023/04/17/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <id>http://example.com/2023/04/17/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</id>
    <published>2023-04-17T13:46:37.000Z</published>
    <updated>2023-08-07T09:53:33.502Z</updated>
    
    <content type="html"><![CDATA[<h2 id="何为损失函数"><a href="#何为损失函数" class="headerlink" title="何为损失函数"></a>何为损失函数</h2><h2 id="常见的损失函数"><a href="#常见的损失函数" class="headerlink" title="常见的损失函数"></a>常见的损失函数</h2><h3 id="均方差（MSE）损失（Mean-Squared-Error-Loss）"><a href="#均方差（MSE）损失（Mean-Squared-Error-Loss）" class="headerlink" title="均方差（MSE）损失（Mean Squared Error Loss）"></a>均方差（MSE）损失（Mean Squared Error Loss）</h3><p>均方差（MSE）损失是机器学习、深度学习回归任务中最常用的一种损失函数，也称为L2 Loss，它是模型预测值 $\hat y$ 与真实样本值 $y$ 之间差值的平方和。<br>$$<br>L_2(x)&#x3D;(y-\hat y)^2<br>$$</p><p>$$<br>J_{MSE}&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^{N}(y_i-\hat y_i)^2<br>$$<br>令 n&#x3D;1，以$y-\hat y$为横轴，MSE值为纵轴，得函数图形如下：</p><p>可见MSE函数曲线光滑连续且处处可导，便于使用梯度下降算法，并且随着误差的减小，梯度也在减小，有利于收敛。</p><p>由平方项可知，当 $y-\hat y &lt; 1$，MSE给予较小的惩罚，缩小误差；当 $y-\hat y &gt; 1$，MSE给予较大的惩罚，放大误差；可知MSE对离群点比较敏感，受其影响较大。</p><p>如果样本中存在离群点，MSE会给离群点更高的权重放大误差，这就会牺牲其他正常点数据的预测效果，最终降低整体的模型性能。如图：</p><h3 id="平均绝对误差（MAE）损失（Mean-Absolute-Error-Loss）"><a href="#平均绝对误差（MAE）损失（Mean-Absolute-Error-Loss）" class="headerlink" title="平均绝对误差（MAE）损失（Mean Absolute Error Loss）"></a>平均绝对误差（MAE）损失（Mean Absolute Error Loss）</h3><p>平均绝对误差（MAE）是另一种常用的回归损失函数，它是模型预测值 $\hat y$ 与真实样本值 $y$ 之差绝对值的和，表示了预测值的平均误差幅度，而不需要考虑误差的方向，范围是0到∞，其公式如下所示：<br>$$<br>L_2(x)&#x3D;\vert y-\hat y \vert<br>$$</p><p>$$<br>J_{MAE}&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^{N}\vert y_i-\hat y_i \vert<br>$$<br>令 n&#x3D;1，以$y-\hat y$为横轴，MAE值为纵轴，得函数图形如下：</p><p>可见MAE函数曲线连续呈线性增长，但是在$y-\hat y &#x3D; 0$ 处不可导，其他地方梯度值为常数，具有一定的稳定性，不会导致梯度爆炸问题，具有较为稳健性的解。</p><p>MAE 对于不同的差值惩罚是固定的，因此对离群点不太敏感，受离群点的影响小。如图：</p><p><strong>MSE和MAE的选择</strong></p><ul><li>从梯度的求解以及收敛上，MSE 是优于 MAE 的。MSE处处可导，而且梯度值也是动态变化的，能够快速的收敛；而 MAE 在 0 点处不可导，且其梯度保持不变。对于很小的损失值其梯度也很大，在深度学习中，需要使用变化的学习率，在损失值很小时降低学习率。</li><li>对离群点需要处理时，MAE 优于 MSE。</li></ul><table><thead><tr><th align="center">L1 Loss</th><th align="center">L2 Loss</th></tr></thead><tbody><tr><td align="center">鲁棒性好</td><td align="center">鲁棒性差</td></tr><tr><td align="center">不稳定解</td><td align="center">稳定解</td></tr><tr><td align="center">可能多个解</td><td align="center">唯一解</td></tr></tbody></table><p>（1）鲁棒性<br>L1 Loss 之所以是鲁棒的，是因为它能<strong>处理数据中的异常值</strong>。这或许在那些异常值可能被安全地和有效地忽略的研究中很有用。如果需要考虑任一或全部的异常值，那么 L1 Loss 是更好的选择。<br>L2 Loss将误差平方化（误差大于1，会放大误差；误差小于1，会缩小误差），因此如果某个样本为异常值，模型就需要调整以适应某个的异常值，这会牺牲许多原来正常的样本，因为这些正常样本的误差比这个异常值的误差小得多。</p><p>（2）稳定性<br>L1 Loss 的不稳定性意味着对于数据集的一个小的水平方向的波动，回归线也许会跳跃很大（如，在转折点处求导）。在一些数据结构上，该方法有许多连续解；但是，对数据集的一个微小移动，就会跳过某个数据结构在一定区域内的许多连续解。在跳过这个区域内的解后，最小绝对值偏差线可能会比之前的线有更大的倾斜。<br>相反地，L2 Loss 的解是稳定的，因为对于一个数据点的任何微小波动，回归线总是只会发生轻微移动；也就说，回归参数是数据集的连续函数。</p><h3 id="Smooth-L1-Loss"><a href="#Smooth-L1-Loss" class="headerlink" title="Smooth L1 Loss"></a>Smooth L1 Loss</h3><p>Smooth L1 Loss 将 L1 原来的折点附近处进行光滑，在Faster R-CNN以及SSD中对边框的回归使用的损失函数都是Smooth L1。<br>$$<br>SmoothL_1(x)&#x3D;\begin{cases}<br>            0.5x^2 &amp; \vert x \vert &lt;1 \[2ex]<br>            \vert x \vert -0.5 &amp; otherwise<br>                \end{cases}<br>$$<br>$ x&#x3D;y-\hat y$ 为真实样本值 $y$ 与模型预测值 $\hat y$ 之差</p><p>smooth L1损失函数曲线如下图所示，作者这样设置的目的是想让loss对于离群点更加鲁棒，相比于L2损失函数，其对离群点（指的是距离中心较远的点）、异常值（outlier）不敏感，可控制梯度的量级使训练时不容易跑飞。</p><p><strong>损失函数对x求导</strong></p><p>其中 x 为预测框与ground truth之间的差异：</p><p>$$<br>L_2(x)&#x3D;x^2<br>\[2ex]<br>\frac{\partial L_2(x)}{\partial x}&#x3D;2x<br>$$<br>当 x 增大时，L2 Loss的损失也增大， 这就导致在训练初期，预测值与 groud truth 差异过于大时，损失函数对预测值的梯度十分大。</p><p>$$<br>L_1(x)&#x3D;\vert x \vert<br>\[2ex]<br>\frac{\partial L_1(x)}{\partial x}&#x3D;\begin{cases}1 &amp; x&gt;0<br>\[2ex]<br>-1 &amp; otherwise<br>\end{cases}<br>$$</p><p>L1 Loss 对 x 的导数为常数，在训练的后期，预测值与ground truth差异很小时，L1 Loss 的导数的绝对值仍然为1，而 learning rate 如果不变，损失函数将在稳定值附近波动，难以继续收敛以达到更高精度。</p><p>$$<br>\frac{\partial SmoothL_1(x)}{\partial x}&#x3D;\begin{cases}<br>            x &amp; \vert x \vert &lt;1 \[2ex]<br>            \pm 1 &amp; otherwise<br>                \end{cases}<br>$$<br>Smooth L1，在 $\vert x \vert &lt;1$ 时，梯度随着 $\vert x \vert$ 变小而变小。 而当$\vert x \vert &gt; 1$ 时，对 $x$ 的梯度的上限为1，也不会太大以至于破坏网络参数。Smooth L1 完美的避开了 L1 Loss 和L2 Loss 作为损失函数的缺陷。</p><h3 id="Huber-Loss"><a href="#Huber-Loss" class="headerlink" title="Huber  Loss"></a>Huber  Loss</h3><p>$$<br>L_{\delta}(y,f(x))&#x3D;\begin{cases}\frac{1}{2}(y-f(x))^2 &amp; \vert y-f(x) \vert \leq \delta<br>\[2ex]<br>\delta \vert y-f(x) \vert -\frac{1}{2} \delta^2 &amp;\vert y-f(x) \vert &gt; \delta<br>\end{cases}<br>$$</p><p>Huber Loss 是 L1 Loss 和 L2 Loss 两者的结合，在误差很小的时候采用平方误差，误差很大的时候采用绝对误差，这个分界点由超参数 $\delta$ 来控制。</p><p>误差损失在 $[0-\delta,0+\delta]$ 之间时，Huber 等价为 MSE；误差损失在 $(-\infty,\delta)和(\delta,+\infty)$ 之间时 Huber 等价为 MAE；这样，当误差较大时，使用MAE对离群点不那么敏感；在误差较小时使用MSE，能够快速的收敛；</p><p>Smooth L1其实就是Huber Loss 的特殊情况，可以看作超参数 $\delta&#x3D;1$ 的Huber函数。。</p><h3 id="Log-Cosh-Loss"><a href="#Log-Cosh-Loss" class="headerlink" title="Log-Cosh Loss"></a>Log-Cosh Loss</h3><p>$$<br>L(y,\hat y)&#x3D;\sum_{i&#x3D;1}^{n}log(cosh(\hat y_i-y_i))<br>$$</p><p>Log-Cosh Loss 是比 L2 Loss 更光滑的损失函数，是误差值的双曲余弦的对数。</p><p>对于较小的误差 $\vert y-f(x) \vert $ ，其近似于MSE，收敛下降较快；对于较大的误差$\vert y-f(x) \vert $其近似等于$\vert y-f(x) \vert -log(2)$,类似于MAE，不会受到离群点的影响。 Log-Cosh具有Huber 损失的所有有点，且不需要设定超参数。</p><p>相比于 Huber，Log-Cosh 求导比较复杂，计算量较大，在深度学习中使用不多。不过，Log-Cosh处处二阶可微，这在一些机器学习模型中，还是很有用的。例如 XGBoost，就是采用牛顿法来寻找最优点。而牛顿法就需要求解二阶导数（Hessian）。因此对于诸如 XGBoost 这类机器学习框架，损失函数的二阶可微是很有必要的。但 Log-cosh 损失也并非完美，其仍存在某些问题。比如误差很大的话，一阶梯度和 Hessian 会变成定值，这就导致 XGBoost 出现缺少分裂点的情况。</p><h3 id="Quantile-Loss-分位数损失"><a href="#Quantile-Loss-分位数损失" class="headerlink" title="Quantile Loss 分位数损失"></a>Quantile Loss 分位数损失</h3><p>$$<br>L_\gamma(y,\hat y)&#x3D;\sum_{i:y_i&lt;\hat y_i}(1-\gamma) \vert y_i-\hat y_i \vert<br>+\sum_{i:y_i \geq \hat y_i}\gamma \vert y_i-\hat y_i \vert<br>$$</p><p>该函数是一个分段函数，$\gamma$ 为分位数系数，$y$ 为真实值，$\hat y$ 为预测值。根据预测值和真实值的大小，分两种情况来开考虑。$\hat y &gt; y$ 为高估，预测值比真实值大；$\hat y &lt; y$ 为低估，预测值比真实值小，<strong>使用不同系数来控制高估和低估在整个损失值的权重，进而实现分位数回归</strong> 。</p><p>特别的，当$\gamma&#x3D;0.5$  时，分位数损失退化为平均绝对误差 MAE，也可以将 MAE 看成是分位数损失的一个特例：中位数损失。下图是取不同的中位点[0.25,0.5,0.7][0.25,0.5,0.7] 得到不同的分位数损失函数的曲线，也可以看出0.5时就是MAE。</p><blockquote><p><a href="https://www.cnblogs.com/wangguchangqing/p/12021638.html">回归损失函数1：L1 loss, L2 loss以及Smooth L1 Loss的对比 - Brook_icv - 博客园 (cnblogs.com)</a></p><p><a href="https://blog.csdn.net/weixin_41940752/article/details/93159710">(44条消息) L1、L2、smooth L1三类损失函数_happy1yao的博客-CSDN博客</a></p><p><a href="https://cloud.tencent.com/developer/article/1950150">六个深度学习常用损失函数总览：基本形式、原理、特点 - 腾讯云开发者社区-腾讯云 (tencent.com)</a></p><p><a href="https://www.cnblogs.com/wangguchangqing/p/12054772.html">回归损失函数2 ： HUber loss,Log Cosh Loss,以及 Quantile Loss - Brook_icv - 博客园 (cnblogs.com)</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;何为损失函数&quot;&gt;&lt;a href=&quot;#何为损失函数&quot; class=&quot;headerlink&quot; title=&quot;何为损失函数&quot;&gt;&lt;/a&gt;何为损失函数&lt;/h2&gt;&lt;h2 id=&quot;常见的损失函数&quot;&gt;&lt;a href=&quot;#常见的损失函数&quot; class=&quot;headerlink&quot; ti</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>激活函数</title>
    <link href="http://example.com/2023/04/15/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>http://example.com/2023/04/15/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</id>
    <published>2023-04-15T13:46:37.000Z</published>
    <updated>2023-08-07T09:52:34.853Z</updated>
    
    <content type="html"><![CDATA[<h2 id="何为激活函数"><a href="#何为激活函数" class="headerlink" title="何为激活函数"></a>何为激活函数</h2><p>激活函数（Activation Function）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的复杂模式。在神经元中，输入的input经过一系列加权求和后作用于另一个函数，这个函数就是这里的激活函数。</p><p>激活函数可以分为线性激活函数（线性方程控制输入到输出的映射，如f(x)&#x3D;x等）以及非线性激活函数（非线性方程控制输入到输出的映射，比如Sigmoid、Tanh、ReLU、LReLU、PReLU、Swish 等）</p><blockquote><p>因为神经网络中每一层的输入输出都是一个线性求和的过程，下一层的输出只是承接了上一层输入函数的线性变换，所以如果没有激活函数，那么无论你构造的神经网络多么复杂，有多少层，最后的输出都是输入的线性组合，纯粹的线性组合并不能够解决更为复杂的问题。而引入激活函数之后，我们会发现常见的激活函数都是非线性的，因此也会给神经元引入非线性元素，使得神经网络可以逼近其他的任何非线性函数，这样可以使得神经网络应用到更多非线性模型中。</p></blockquote><p>为了增强网络的表示能力和学习能力，神经网络的激活函数都是<strong>非线性</strong>的，通常具有以下几点性质：</p><ul><li>连续并可导（允许少数点上不可导），<strong>可导</strong>的激活函数可以直接利用<strong>数值优化</strong>的方法来学习网络参数；</li><li>激活函数及其导数要尽可能<strong>简单</strong>一些，太复杂不利于提高网络计算率；</li><li>激活函数的导函数值域要在一个<strong>合适的区间</strong>内，不能太大也不能太小，否则会影响训练的效率和稳定性。</li></ul><h2 id="常见的激活函数"><a href="#常见的激活函数" class="headerlink" title="常见的激活函数"></a>常见的激活函数</h2><h3 id="Sigmoid-函数（Logistic-函数）"><a href="#Sigmoid-函数（Logistic-函数）" class="headerlink" title="Sigmoid 函数（Logistic 函数）"></a>Sigmoid 函数（Logistic 函数）</h3><p>用于<strong>隐层神经元</strong>输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。在特征相差比较复杂或是相差不是特别大时效果比较好。<br>$$<br>\sigma(x)&#x3D;\frac{1}{1+e^{-x}}<br>$$</p><p>$$<br>\sigma’(x)&#x3D;\frac{e^{-x}}{(1+e^{-x})^2}&#x3D;\sigma(x)(1-\sigma(x))<br>$$</p><p>Sigmoid 激活函数的图像是 S 形</p><p><strong>优点</strong></p><ul><li>Sigmoid 函数的输出范围是 0 到 1。由于输出值限定在 0 到1，因此它对每个神经元的输出进行了归一化；</li><li>可用于将<strong>预测概率</strong>作为输出的模型。由于概率的取值范围是 0 到 1，因此 Sigmoid 函数非常合适；</li><li><strong>梯度平滑</strong>，避免「跳跃」的输出值；</li><li>函数是可导且易于求导。可以找到任意两个点的 sigmoid 曲线的斜率；</li><li>明确的预测，输入很大或很小时输出非常接近 1 或 0。</li></ul><p><strong>存在的不足</strong></p><ul><li><strong>梯度消失</strong>：Sigmoid 函数趋近 0 和 1 的时候<strong>变化率</strong>会变得平坦，也就是说，Sigmoid 的梯度趋近于 0。神经网络使用 Sigmoid 激活函数进行反向传播时，输出接近 0 或 1 的神经元其梯度趋近于 0。这些神经元叫作饱和神经元。因此，这些神经元的<strong>权重不会更新</strong>。此外，与此类神经元<strong>相连</strong>的神经元的权重也<strong>更新得很慢</strong>。该问题叫作梯度消失。因此，想象一下，如果一个大型神经网络包含 Sigmoid 神经元，而其中很多个都处于饱和状态，那么该网络无法执行反向传播。</li><li><strong>不以零为中心</strong>：Sigmoid 输出<strong>不以零为中心</strong>的,，输出恒大于0，非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（Bias Shift），并进一步使得梯度下降的收敛速度变慢。</li><li><strong>计算成本高昂</strong>：exp() 函数与其他非线性激活函数相比，计算成本高昂，计算机运行起来速度较慢。</li></ul><h3 id="Tanh-双曲正切-激活函数"><a href="#Tanh-双曲正切-激活函数" class="headerlink" title="Tanh&#x2F;双曲正切 激活函数"></a>Tanh&#x2F;双曲正切 激活函数</h3><p>Tanh 激活函数又叫作双曲正切激活函数（hyperbolic tangent activation function）。与 Sigmoid 函数类似，Tanh 函数也使用真值，但 Tanh 函数将其压缩至-1 到 1 的区间内。与 Sigmoid 不同，Tanh 函数的输出以零为中心，因为区间在-1 到 1 之间。</p><p>$$<br>f(x)&#x3D;tanh(x)&#x3D;\frac{e^x-e^{-x}}{e^x+e^{-x}}&#x3D;\frac{1-e^{-2x}}{1+e^{-2x}}&#x3D;\frac{2}{1+e^{-2x}}-1<br>$$<br>Tanh 函数可以看作放大并平移的Sigmoid 函数<br>$$<br>tanh(x)&#x3D;2sigmoid(2x)-1<br>$$<br>tanh 激活函数的图像也是 S 形</p><p>在实践中，Tanh 函数的使用优先性高于 Sigmoid 函数。负数输入被当作负值，零输入值的映射接近零，正数输入被当作正值：</p><ul><li>当输入较大或较小时，输出几乎是平滑的并且梯度较小，这不利于权重更新。二者的区别在于输出间隔，tanh 的<strong>输出间隔为 1</strong>，并且整个函数<strong>以 0 为中心</strong>，<strong>比 sigmoid 函数更好</strong>；</li><li>在 tanh 图中，负输入将被强映射为负，而零输入被映射为接近零。</li></ul><p><strong>存在的不足</strong></p><ul><li>Tanh 函数也会有<strong>梯度消失</strong></li></ul><p>在一般的二元分类问题中，tanh 函数用于<strong>隐藏层</strong>，而 sigmoid 函数用于输出层，但这并不是固定的，需要根据特定问题进行调整。</p><h3 id="ReLU激活函数"><a href="#ReLU激活函数" class="headerlink" title="ReLU激活函数"></a>ReLU激活函数</h3><p>ReLU函数又称为修正线性单元（Rectified Linear Unit），是一种分段线性函数，其<strong>弥补</strong>了sigmoid函数以及tanh函数的<strong>梯度消失</strong>问题，在目前的深度神经网络中被广泛使用。ReLU函数本质上是一个斜坡（ramp）函数。<br>$$<br>ReLU(x)&#x3D;\begin{cases}x,&amp; x&gt;0 \[2ex]  0,&amp; x\leq0\end{cases}&#x3D;max(0,x)<br>$$<br><strong>优点</strong></p><ul><li><strong>当输入为正时，导数为1</strong>，一定程度上改善了梯度消失问题，加速梯度下降的收敛速度；</li><li>ReLU 函数中只存在线性关系，因此它的计算速度快。</li><li>被认为具有生物学合理性（Biological Plausibility）,比如单侧抑制、宽兴奋边界（即兴奋程度可以非常高）</li><li>使用Relu会使部分神经元为0，这样就造成了网络的<strong>稀疏性</strong>，并且减少了参数之间的相互依赖关系，<strong>缓解了过拟合问题</strong>的发生。</li></ul><p><strong>存在的不足</strong></p><ul><li><strong>Dead ReLU 问题</strong>。当输入为负时，ReLU 完全失效，在正向传播过程中，这不是问题。有些区域很敏感，有些则不敏感。但是在反向传播过程中，如果输入负数，则梯度将完全为零；</li></ul><blockquote><p>ReLU神经元在训练时比较容易“死亡”。在训练时，如果参数在一次不恰当的更新后，第一个隐藏层中的某个ReLU 神经元在所有的训练数据上都不能被激活，那么这个神经元自身参数的梯度永远都会是0，在以后的训练过程中永远不能被激活，这种现象称为<strong>Dead ReLU问题</strong>，并且也有可能会发生在其他隐藏层。</p></blockquote><ul><li>不以零为中心，ReLU 函数的输出<strong>不以零为中心</strong>，ReLU 函数的输出为 0 或正数,给后一层的神经网络引入偏置偏移，会影响梯度下降的效率。</li></ul><h3 id="Leaky-ReLU-激活函数"><a href="#Leaky-ReLU-激活函数" class="headerlink" title="Leaky ReLU 激活函数"></a>Leaky ReLU 激活函数</h3><p>为了解决 ReLU 激活函数中的梯度消失问题， 我们使用Leaky ReLU——该函数试图修复 Dead ReLU 问题。<br>$$<br>LeakyReLU(X)&#x3D;\begin{cases}x,&amp; x&gt;0\[2ex] \gamma x,&amp; x\leq0\end{cases}&#x3D;max(0,x)+\gamma min(0,x)<br>$$<br>$\gamma$一般是个很小的数。<br>$$<br>LeakyReLU(X)&#x3D;max(x,\gamma x)<br>$$<br>当$\gamma$&lt; 1，相当于是一个比较简单的Maxout单元。</p><h3 id="Parametric-ReLU-激活函数"><a href="#Parametric-ReLU-激活函数" class="headerlink" title="Parametric ReLU 激活函数"></a>Parametric ReLU 激活函数</h3><p>Leaky ReLU 是让 x 乘常数项，而 Parametric ReLU 让 x 乘超参数。</p><p>$$<br>PReLU_i(X)&#x3D;\begin{cases}x,&amp; x&gt;0\[2ex]  \gamma_i x,&amp; x\leq0\end{cases}&#x3D;max(0,x)+\gamma_i min(0,x)<br>$$<br>其中$\gamma_i$是超参数，对应了$x\leq0$时函数的斜率。这里引入了一个随机的超参数，它可以被学习，可以对它进行反向传播。不同神经元可以有不同的参数，其中的i对应了第i个神经元，这使神经元能够选择负区域最好的梯度</p><p>如果 $\gamma_i&#x3D;0$ ，那么 PReLU 就退化为 ReLU；</p><p>如果 $\gamma_i$ 为一个很小的常数，则 PReLU 可以看作 Leaky ReLU;</p><p>PReLU 可以允许不同神经元具有不同的参数，也可以一组神经元共享一个参数。</p><h3 id="ELU-激活函数"><a href="#ELU-激活函数" class="headerlink" title="ELU 激活函数"></a>ELU 激活函数</h3><p>ELU（Exponential Linear Unit） 的提出同样也是针对解决 ReLUDead ReLU的问题，由Djork等人提出,被证实有较高的噪声鲁棒性。ELU激活函数对 $x$ 小于零的情况采用类似指数计算的方式进行输出。与 ReLU 相比，ELU 有负值，这会使激活的平均值接近零。<strong>均值激活接近于零可以使学习更快，因为它们使梯度更接近自然梯度。</strong><br>$$<br>ELU(X)&#x3D;\begin{cases}x,&amp; x&gt;0\ \alpha(e^x-1),&amp; x\leq0\end{cases}<br>$$<br><strong>优点</strong></p><ul><li>解决了 Dead ReLU 问题，输出的平均值接近 0，以 0 为中心；</li><li>ELU 通过减少偏置偏移的影响，使正常梯度更接近于单位自然梯度，从而使均值向零加速学习；</li><li>ELU 在较小的输入下会饱和至负值，从而减少前向传播的变异和信息。</li></ul><p><strong>不足</strong></p><ul><li>计算量较大且强度更高。</li></ul><h3 id="Softmax-激活函数"><a href="#Softmax-激活函数" class="headerlink" title="Softmax 激活函数"></a>Softmax 激活函数</h3><p>Softmax 是用于<strong>多类分类问题</strong>的激活函数，在多类分类问题中，超过两个类标签则需要类成员关系。对于长度为 K 的任意实向量，Softmax 可以将其压缩为长度为 K，值在（0，1）范围内，并且向量中元素的总和为 1 的实向量。<br>$$<br>S_i&#x3D;\frac{e^{z_i}}{\sum_{j&#x3D;1}^K e^{z_j}}<br>$$</p><p>Softmax 函数的分母结合了原始输出值的所有因子，这意味着 Softmax 函数获得的<strong>各种概率彼此相关</strong>。</p><p><strong>存在的不足</strong></p><ul><li>在零点不可微；</li><li>负输入的梯度为零，这意味着对于该区域的激活，权重不会在反向传播期间更新，因此会产生永不激活的死亡神经元。</li></ul><h3 id="Swish-激活函数"><a href="#Swish-激活函数" class="headerlink" title="Swish 激活函数"></a>Swish 激活函数</h3><p>Swish激活函数又叫作自门控激活函数，它由谷歌的研究者发布。<br>$$<br>Swish(x)&#x3D;x·Sigmoid(\beta x)&#x3D;x·sigmoid(\beta x)&#x3D;\frac{x}{1+e^{-\beta x}}<br>$$<br>当 $sigmoid(\beta x)$接近于1时，门处于“<strong>开</strong>”状态，激活函数的输出近似于x本身；</p><p>当 $sigmoid(\beta x)$接近于0时，门处于“<strong>关</strong>”状态，激活函数的输出近似于0；</p><p>图</p><p>当 $\beta&#x3D;0$时，Swish 函数变成线性函数 �&#x2F;2 ;</p><p>当 $\beta&#x3D;1$时，Swish 函数在 $x$&gt;0 时近似线性，在 $x$&lt;0 时近似饱和，同时具有一定的非单调性；</p><p>当 $\beta$ 趋于正无穷时，$sigmoid(\beta x)$ 函数趋向于离散的0-1函数，Swish 函数近似为 ReLU 函数；</p><p>因此，<strong>Swish 函数可以看作线性函数和ReLU 函数之间的非线性插值函数</strong>，<strong>其程度由参数 $\beta$ 控制。</strong></p><h3 id="Maxout-激活函数"><a href="#Maxout-激活函数" class="headerlink" title="Maxout 激活函数"></a>Maxout 激活函数</h3><p>通常情况下，如果激活函数采用sigmoid函数的话，在前向传播过程中，隐含层节点的输出表达式为：</p><p>$$<br>h_i(x)&#x3D;sigmoid(x^TW_{…i}+b_i)<br>$$<br>一般情况下，W是2维的，这里表示的 i 是第 i 列，…表示的是对应第 i 列中的所有行。</p><p>在Maxout网络中，其隐含层节点的输出表达式为：</p><p>$$<br>h_i(x)&#x3D;max_{j\in[1,k]} \space z_{ij} \<br>z_{ij}&#x3D;x^TW_{…ij}+b_{ij} \space ,W\in R^{d×m×k}<br>$$<br>这里的 W 是3维的，尺寸为 d×m×k，其中 d 表示输入层节点的个数，m 表示隐含层节点的个数，k表示每个隐含层节点对应了 k 个”隐隐含层”节点，这k个”隐隐含层”节点都是线性输出的，而 maxout 的每个节点就是取这 k 个”隐隐含层”节点输出值中最大的那个值。因为激发函数中有了max操作，所以整个 maxout 网络也是一种非线性的变换。</p><p>Maxout 激活函数是一个可学习的激活函数，因为我们 W 参数是学习变化的。任何一个凸函数，都可以由线性分段函数进行逼近近似。ReLU、abs激活函数，看成是分成两段的线性函数，如下示意图所示：</p><p><strong>优点</strong></p><ul><li>Maxout的拟合能力非常强，可以拟合任意的凸函数。</li><li>Maxout具有ReLU的所有优点，线性、不饱和性。同时没有ReLU的一些缺点。如：神经元的死亡。</li><li>实验结果表明Maxout与Dropout组合使用可以发挥比较好的效果。</li></ul><p><strong>不足</strong></p><p>每个神经元中有两组(w,b)参数，参数量增加了一倍，这就导致了整体参数的数量激增。</p><h3 id="Softplus激活函数"><a href="#Softplus激活函数" class="headerlink" title="Softplus激活函数"></a>Softplus激活函数</h3><p>Softplus 函数是 Sigmoid 函数原函数，Softplus 可以看做是ReLU函数的一个平滑版本。<br>$$<br>Softplus(x)&#x3D;f(x)&#x3D;log(1+e^x) \<br>f’(x)&#x3D;\frac{e^x}{1+e^x}&#x3D;\frac{1}{1+e^{-x}}&#x3D;sigmoid(x)<br>$$<br>图</p><p>Softplus函数加了 1 是为了保证非负性。Softplus可以看作是强制非负校正函数max(0,x)平滑版本。</p><p>Softplus 函数其导数刚好是 Sigmoid 函数，Softplus 函数虽然也具有单侧抑制、宽兴奋边界的特性，<strong>却没有稀疏激活性</strong>。</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/364620596">深度学习笔记：如何理解激活函数？（附常用激活函数） - 知乎 (zhihu.com)</a></p><p><a href="https://www.cnblogs.com/makefile/p/activation-function.html">激活函数(ReLU, Swish, Maxout) - 康行天下 - 博客园 (cnblogs.com)</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;何为激活函数&quot;&gt;&lt;a href=&quot;#何为激活函数&quot; class=&quot;headerlink&quot; title=&quot;何为激活函数&quot;&gt;&lt;/a&gt;何为激活函数&lt;/h2&gt;&lt;p&gt;激活函数（Activation Function）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>TensorFlow 笔记2</title>
    <link href="http://example.com/2023/03/29/TensorFlow%20%E7%AC%94%E8%AE%B02/"/>
    <id>http://example.com/2023/03/29/TensorFlow%20%E7%AC%94%E8%AE%B02/</id>
    <published>2023-03-29T15:29:38.000Z</published>
    <updated>2023-08-07T09:53:45.827Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据读取处理"><a href="#数据读取处理" class="headerlink" title="数据读取处理"></a><strong>数据读取处理</strong></h2><h3 id="1-文件读取"><a href="#1-文件读取" class="headerlink" title="1. 文件读取"></a>1. 文件读取</h3><p>以下用到的队列都为<code>tf.train.QueueRunner</code>对象，每个 QueueRunner 都负责一个阶段，<code>tf.train.start_queue_runners()</code>函数会要求图中的每个 QueueRunner 启动它的运行队列操作的线程。因此需要在会话中进行<strong>线程操作</strong>（<strong>结束后需回收线程</strong>）。</p><p><code>tf.train.Coordinator()</code><strong>线程协调器</strong>，通过它来对线程进行管理和协调；创建一个线程协调器对象<code>coord = tf.train.Coordinator()</code>，<code>coord.request_stop()</code>：<strong>请求停止</strong>，<code>coord.join(threads= )</code>：<strong>回收线程</strong>。</p><p><code>tf.train.start_queue_runners(sess=,coord=)</code>收集图中所有的队列线程，默认同时启动线程。sess:所在的会话，coord:线程协调器。</p><h4 id="1-1-构造文件名队列"><a href="#1-1-构造文件名队列" class="headerlink" title="1.1 构造文件名队列"></a>1.1 构造文件名队列</h4><p>将需要读取的文件的文件名（一般为相对路径）放入文件队列。</p><p><code>tf.train.string_input_producer(string_tensor,num_epochs=None,shuffle=True)</code></p><ul><li><p>string_tensor：相对路径的一阶张量，一般用<code>[相对路径]</code>传入即可。</p></li><li><p>num_epochs：表示迭代的次数，默认为 None 无限次遍历 tensor 列表。</p></li><li><p>shuffle：bool 类型，表示是否打乱样本的顺序,默认为 True 即生成的样本顺序被打乱了，在批处理的时候不需要再次打乱样本，使用 tf.train.batch函数就可以了；如果shuffle&#x3D;False，就需要在批处理时候使用 tf.train.shuffle_batch函数打乱样本。</p></li></ul><p>将文件名列表交给<code>tf.train.string_input_producer</code>函数。string_input_producer来生成一个<strong>先入先出的队列</strong>，文件阅读器会需要它们来取数据。string_input_producer 提供的可配置参数来设置文件名乱序和最大的训练迭代数，QueueRunner会为每次迭代（epoch）将所有的文件名加入文件名队列中，如果shuffle&#x3D;True的话，会对文件名进行乱序处理。这一过程是比较均匀的，因此它可以产生均衡的文件名队列。</p><p>这个<strong>QueueRunner工作线程是独立于文件阅读器的线程</strong>，因此乱序和将文件名推入到文件名队列这些过程不会阻塞文件阅读器运行。根据你的文件格式，选择对应的文件阅读器，然后将文件名队列提供给阅读器的read方法。阅读器的read方法会输出一个键来表征输入的文件和其中的数据，同时得到一个<strong>字符串标量</strong>，这个字符串标量可以被一个或多个解析器，或者<strong>转换操作将其解码为张量并且构造成为样本。</strong></p><h4 id="1-2-读取与解码"><a href="#1-2-读取与解码" class="headerlink" title="1.2 读取与解码"></a>1.2 读取与解码</h4><h5 id="1-2-1-文件读取器"><a href="#1-2-1-文件读取器" class="headerlink" title="1.2.1 文件读取器"></a>1.2.1 文件读取器</h5><p>根据文件的内容格式选择相应的文件读取器</p><p><code>tf.TextLineReader</code>：读取文本文件逗号分隔值(CSV)格式，默认一次读取一行。</p><p><code>tf.WholeFileReader</code>：读取图片文件，默认一次读取一张图片。</p><p><code>tf.FixedLengthRecordReader(record_bytes)</code>：读取二进制文件（每个记录是固定数量字节的二进制文件），<code>record_bytes</code>指定每次读取一个样本的字节数。</p><p><code>tf.TFRecordReader</code>：读取TFRecords文件。</p><h5 id="1-2-2文件内容解码器"><a href="#1-2-2文件内容解码器" class="headerlink" title="1.2.2文件内容解码器"></a>1.2.2文件内容解码器</h5><p>针对不同格式的内容进行相对应的解码操作，解码为统一Tensor格式。</p><p><code>tf.decode_csv()</code>: 解码文本文件内容，将CSV转换为张量，与<code>tf.TextLineReader</code>搭配使用。<br><code>tf.image.decode_jpeg </code>and<code>tf.image.decode_png</code>(contents即样本)<br>将JPEG编码（PNG编码）的图像解码为uint8张量，3-D形状:[height, width, channels]，与<code>tf.WholeFileReader</code>搭配使用。<br><code>tf.decode_raw()</code>︰解码二进制文件内容,与<code>tf.FixedLengthRecordReader</code>搭配使用，二进制读取为uint8类型。</p><p>解码阶段默认所有内容都解码为unit8类型，uint8保存节省空间，若想提高计算精度则可通过<code>tf.cast()</code>进行类型转换为float32。</p><h4 id="1-3-批处理"><a href="#1-3-批处理" class="headerlink" title="1.3 批处理"></a>1.3 批处理</h4><p><code>tf.train.batch(tensors, batch_size, num_threads = 1, capacity = 32,name=None)</code></p><p>读取指定大小（个数）的张量， 单张图片 [height width channels] 多张图片 [batch height width channels]。</p><ul><li>tensors：可以是包含张量的列表，批处理的内容放到列表当中。</li><li>batch_size：从队列中读取的批处理大小。</li><li>num_threads：进入队列的线程数。</li><li>capacity：整数，队列中元素的最大数量。</li></ul><p><code>tf.train.shuffle_batch(tensors,batch_size,capacity,min_after_dequeue,num_threads=1) </code>： 乱序读取指定大小（个数）的张量。</p><h3 id="2-图片读取"><a href="#2-图片读取" class="headerlink" title="2. 图片读取"></a>2. 图片读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">picture_read</span>(<span class="params">file_list</span>):</span><br><span class="line">    <span class="comment"># 1. 构建文件名队列</span></span><br><span class="line">    file_queue = tf.train.string_input_producer(file_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;file_queue:&#x27;</span>,file_queue)</span><br><span class="line">    <span class="comment"># 2. 文件读取与解码</span></span><br><span class="line">    reader = tf.WholeFileReader()  <span class="comment"># 图片读取器</span></span><br><span class="line">    <span class="comment"># key为文件名，value为一张图片的原始编码形式</span></span><br><span class="line">    key, value = reader.read(file_queue)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;key&#x27;</span>, key)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;value&#x27;</span>, value)</span><br><span class="line">    image = tf.image.decode_jpeg(value)  <span class="comment"># 读取的是什么格式，就decode什么格式</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image:&#x27;</span>,image)  <span class="comment"># 形状不定</span></span><br><span class="line">    <span class="comment"># 图片形状、类型修改</span></span><br><span class="line">    image_resize = tf.image.resize_images(image, [<span class="number">200</span>, <span class="number">200</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image_resize:&#x27;</span>,image_resize)</span><br><span class="line">    image_resize.set_shape(shape=[<span class="number">200</span>, <span class="number">200</span>, <span class="number">3</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image_resize&#x27;</span>,image_resize)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 批处理</span></span><br><span class="line">    image_batch = tf.train.batch([image_resize], batch_size=<span class="number">100</span>, num_threads=<span class="number">1</span>, capacity=<span class="number">100</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image_batch:&#x27;</span>,image_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># 创建线程协调员</span></span><br><span class="line">        coord = tf.train.Coordinator()</span><br><span class="line">        <span class="comment"># 开启线程</span></span><br><span class="line">        threads = tf.train.start_queue_runners(sess=sess, coord=coord)</span><br><span class="line">        key_new,value_new,image_new,image_resize_new,image_batch_new = sess.run([key,value,image,image_resize,image_batch])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;key_new:\n&#x27;</span>,key_new)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;value_new:\n&#x27;</span>,value_new)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_new:\n&#x27;</span>,image_new)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_resize_new:\n&#x27;</span>,image_resize_new)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_batch_new:\n&#x27;</span>,image_batch_new)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 停止线程 回收线程</span></span><br><span class="line">        coord.request_stop()</span><br><span class="line">        coord.join(threads)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    file_name = os.listdir(<span class="string">&#x27;./dog&#x27;</span>)  <span class="comment"># 返回指定路径下的文件和文件夹列表</span></span><br><span class="line">    <span class="comment"># 路径 + 文件名 形成列表</span></span><br><span class="line">    file_list = [os.path.join(<span class="string">&#x27;./dog&#x27;</span>, file) <span class="keyword">for</span> file <span class="keyword">in</span> file_name]</span><br><span class="line">    <span class="comment"># print(file_name)</span></span><br><span class="line">    <span class="comment"># print(file_list)</span></span><br><span class="line">    picture_read(file_list)</span><br></pre></td></tr></table></figure><h3 id="3-CIFAR10二进制读取"><a href="#3-CIFAR10二进制读取" class="headerlink" title="3. CIFAR10二进制读取"></a>3. CIFAR10二进制读取</h3><blockquote><p>CIFAR10数据集官网： <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></p></blockquote><p>数据集分为五个训练批次和一个测试批次，每个批次有 10000 张图像。测试批次恰好包含来自每个类别的 1000 个随机选择的图像。训练批次包含随机顺序的剩余图像，但一些训练批次可能包含来自一个类的图像多于另一个。在它们之间，训练批次恰好包含来自每个类别的 5000 张图像。</p><p>这些文件中的每一个格式如下，数据中每个样本包含了特征值和目标值:</p><p><strong>cifar10 的特征值是 image(3072Bytes) 目标值是 label 0-9 (1Bytes)。</strong></p><p>&lt;1×标签&gt;&lt;3072×像素&gt;<br>                …<br>&lt;1×标签&gt;&lt;3072×像素&gt;<br><strong>第一个字节是第一个图像的标签，它是一个0-9范围内的数字。接下来的3072个字节是图像像素的值。前1024个字节是红色通道值，下1024个绿色，最后1024个蓝色。</strong>值以行优先顺序存储，因此前32个字节是图像第一行的红色通道值。每个文件都包含10000个这样的3073字节的“行”图像，但没有任何分隔行的限制。因此每个文件应该完全是30730000字节长。<br>即一个样本的形式为： 1+1024r+1024g+1024b&#x3D;3073个字节</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CIFAR10</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化操作</span></span><br><span class="line">        self.height = <span class="number">32</span></span><br><span class="line">        self.width = <span class="number">32</span></span><br><span class="line">        self.channels = <span class="number">3</span></span><br><span class="line">        <span class="comment"># 标签和像素 字节数</span></span><br><span class="line">        self.image_bytes = self.height * self.width * self.channels</span><br><span class="line">        self.label_bytes = <span class="number">1</span></span><br><span class="line">        self.all_bytes = self.label_bytes + self.image_bytes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_and_decode</span>(<span class="params">self,file_list</span>):</span><br><span class="line">        <span class="comment"># 1. 构建文件名队列</span></span><br><span class="line">        file_queue = tf.train.string_input_producer(file_list)</span><br><span class="line">        <span class="comment"># 2. 读取与解码</span></span><br><span class="line">        reader = tf.FixedLengthRecordReader(self.all_bytes)</span><br><span class="line">        key,value = reader.read(file_queue)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;key:&#x27;</span>,key)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;value:&#x27;</span>,value)</span><br><span class="line">        decode = tf.decode_raw(value,tf.uint8)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;decode:&#x27;</span>,decode) <span class="comment"># 解码后为一维 标签和通道并在一起（第一位标签）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 因此需要 将目标值（标签）和特征值（通道）切片分开</span></span><br><span class="line">        <span class="comment"># tf.slice( tensor , 初始索引 , 个数 )</span></span><br><span class="line">        label = tf.<span class="built_in">slice</span>(decode,[<span class="number">0</span>],[self.label_bytes])</span><br><span class="line">        image = tf.<span class="built_in">slice</span>(decode,[self.label_bytes],[self.image_bytes])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;label:&#x27;</span>,label)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image:&#x27;</span>,image)</span><br><span class="line"></span><br><span class="line">        image_reshaped = tf.reshape(image,shape = [self.channels,self.height,self.width])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_reshaped:&#x27;</span>,image_reshaped)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码图像由shape为[height, width, channels] 的3 - Duint8张量表示。</span></span><br><span class="line">        image_transposed = tf.transpose(image_reshaped,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_transposed:&#x27;</span>,image_transposed)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># uint8转为float32 提高精度</span></span><br><span class="line">        image_cast = tf.cast(image_transposed,tf.float32)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_cast:&#x27;</span>,image_cast)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. 批处理</span></span><br><span class="line">        label_batch,image_batch = tf.train.batch([label,image_cast],batch_size = <span class="number">100</span>,num_threads = <span class="number">1</span>,capacity = <span class="number">100</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;label_batch:&#x27;</span>,label_batch)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_batch:&#x27;</span>,image_batch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            coord = tf.train.Coordinator()</span><br><span class="line">            threads = tf.train.start_queue_runners(sess =sess,coord = coord)</span><br><span class="line">            key_new, value_new, decode_new, label_new, image_new, image_reshaped_new, image_transposed_new, label_batch_new, image_batch_new = sess.run([key, value, decode, label, image, image_reshaped, image_transposed, label_batch, image_batch])</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;key_new: &#x27;</span>, key_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;value_new: &#x27;</span>, value_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;decode_new&#x27;</span>, decode_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;label_new&#x27;</span>, label_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_new&#x27;</span>, image_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_reshaped_new\n&#x27;</span>, image_reshaped_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_transposed_new\n&#x27;</span>, image_transposed_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;label_batch_new\n&#x27;</span>, label_batch_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_batch_new\n&#x27;</span>, image_batch_new)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 停止线程 回收线程</span></span><br><span class="line">            coord.request_stop()</span><br><span class="line">            coord.join(threads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> label_batch_new,image_batch_new</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 返回指定路径下的文件和文件夹列表</span></span><br><span class="line">    file_name = os.listdir(<span class="string">&#x27;./cifar-10-batches-bin&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;file_name:&#x27;</span>,file_name)</span><br><span class="line">    <span class="comment"># 路径 + 文件名  if file[-3:] == &#x27;bin&#x27;: 后缀bin的文件</span></span><br><span class="line">    file_list = [os.path.join(<span class="string">&#x27;./cifar-10-batches-bin&#x27;</span>,file) <span class="keyword">for</span> file <span class="keyword">in</span> file_name <span class="keyword">if</span> file[-<span class="number">3</span>:] == <span class="string">&#x27;bin&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;file_list:&#x27;</span>,file_list)</span><br><span class="line"></span><br><span class="line">    CIFAR10 = CIFAR10()</span><br><span class="line">    label_batch,image_batch = CIFAR10.read_and_decode(file_list)  <span class="comment"># CIFAR10二进制数据读取        </span></span><br></pre></td></tr></table></figure><h3 id="4-TFRecords"><a href="#4-TFRecords" class="headerlink" title="4. TFRecords"></a>4. TFRecords</h3><p>TFRecords 是 Tensorflow 设计的一种内置文件格式，是一种二进制文件，它能更好的利用内存，更方便复制和移动。将二进制数据和标签(训练的类别标签)数据存储在同一个文件中，即特征值和目标值是绑定在一起的。</p><h4 id="4-1-TFRecords存储"><a href="#4-1-TFRecords存储" class="headerlink" title="4.1 TFRecords存储"></a>4.1 TFRecords存储</h4><ol><li><p>建立TFRecord存储器：tf.python_io.TFRecordWriter(path)</p><ul><li>path: TFRecords文件的路径</li><li>方法：<ul><li>write(record):向文件中写入一个字符串记录</li><li>close():关闭文件写入器(通常采用with文件管理器就无需close了)</li></ul></li><li>注：字符串是一个序列化的Example：Example.SerializeToString()</li><li><code>Example.SerializeToString()</code> 将 example 序列化到本地</li></ul></li><li><p>构造每个样本的Example协议块</p><ul><li><p>tf.train.Example(features&#x3D;None)    写入tfrecords文件</p><ul><li>features：<strong>tf.train.Features 类型的特征实例</strong></li><li>return：example格式协议块</li></ul></li><li><p>tf.train.Features(feature&#x3D;None)          构建每个样本的信息键值对</p><ul><li>features:字典数据，key为要保存的名字，<strong>value为tf.train.Feature实例</strong></li><li>return:Features类型</li></ul></li><li><p>tf.train.Feature(**options)</p><ul><li><p>**options：例如：<br><code>bytes_list = tf.train. BytesList(value=[Bytes])</code>     字节<br><code>int64_list = tf.train. Int64List(value=[Value])</code> 整型</p><p><code>float_list = tf.train.FloatList(value=[value])</code>   浮点型</p></li></ul></li></ul></li><li><p>循环将数据填入Example协议内存块</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">write_to_tfrecords</span>(<span class="params">self,label_batch,image_batch</span>):</span><br><span class="line">        <span class="comment"># 将样本的特征值和目标值写入tfrecords</span></span><br><span class="line">        <span class="comment"># print(label_batch.size) # 100</span></span><br><span class="line">        <span class="keyword">with</span> tf.python_io.TFRecordWriter(<span class="string">&#x27;./cifar10.tfrecords&#x27;</span>) <span class="keyword">as</span> writer:</span><br><span class="line">            <span class="comment"># 循环样本数 构造example对象 序列化写入文件</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(label_batch.size):</span><br><span class="line">                image = image_batch[i].tostring()   <span class="comment"># 图片序列化</span></span><br><span class="line">                label = label_batch[i][<span class="number">0</span>]           <span class="comment"># 取出一维数组的值</span></span><br><span class="line">                <span class="comment"># print(&#x27;image:&#x27;,image)</span></span><br><span class="line">                <span class="comment"># print(&#x27;label:&#x27;,label)</span></span><br><span class="line">                example = tf.train.Example(features = tf.train.Features(feature = &#123;</span><br><span class="line">                    <span class="string">&#x27;image&#x27;</span>: tf.train.Feature(bytes_list = tf.train.BytesList(value = [image])),</span><br><span class="line">                    <span class="string">&#x27;label&#x27;</span>: tf.train.Feature(int64_list = tf.train.Int64List(value = [label]))</span><br><span class="line">                &#125;))</span><br><span class="line">                <span class="comment"># 将序列化后的example 写入cifar10.tfrecords文件中</span></span><br><span class="line">                writer.write(example.SerializeToString())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 返回指定路径下的文件和文件夹列表</span></span><br><span class="line">    file_name = os.listdir(<span class="string">&#x27;./cifar-10-batches-bin&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;file_name:&#x27;</span>,file_name)</span><br><span class="line">    <span class="comment"># 路径 + 文件名  if file[-3:] == &#x27;bin&#x27;: 后缀bin的文件</span></span><br><span class="line">    file_list = [os.path.join(<span class="string">&#x27;./cifar-10-batches-bin&#x27;</span>,file) <span class="keyword">for</span> file <span class="keyword">in</span> file_name <span class="keyword">if</span> file[-<span class="number">3</span>:] == <span class="string">&#x27;bin&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;file_list:&#x27;</span>,file_list)</span><br><span class="line"></span><br><span class="line">    CIFAR10 = CIFAR10()</span><br><span class="line">    <span class="comment"># label_batch,image_batch = CIFAR10.read_and_decode(file_list)  # CIFAR10二进制数据读取</span></span><br><span class="line">    CIFAR10.write_to_tfrecords(label_batch,image_batch)   <span class="comment"># tfrecords文件存储</span></span><br></pre></td></tr></table></figure><h4 id="4-2-TFRecords读取"><a href="#4-2-TFRecords读取" class="headerlink" title="4.2 TFRecords读取"></a>4.2 TFRecords读取</h4><p>读取方法跟文件读取流程基本相同，只是在读取和解码阶段时需要有个<strong>解析TFRecords的example协议内存块的过程</strong>。</p><ul><li>tf.parse_single_example(serialized,features&#x3D;None,name&#x3D;None)<ul><li>解析一个单一的Example原型</li><li>serialized：标量字符串Tensor，一个序列化的Example</li><li>features：dict字典数据，键为读取的名字，<strong>值为FixedLenFeature</strong></li><li>return:<strong>一个键值对组成的字典</strong>，键为读取的名字</li></ul></li><li>tf.FixedLenFeature(shape,dtype)<ul><li>shape：输入数据的形状，一般不指定,为空列表</li><li>dtype：输入数据类型，与存储进文件的类型要一致，类型只能是float32,int64,string</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_tfrecords</span>(<span class="params">self,file_list</span>):</span><br><span class="line">        <span class="comment"># 1. 构造文件名队列</span></span><br><span class="line">        file_queue = tf.train.string_input_producer(file_list)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. 读取与解码</span></span><br><span class="line">        reader = tf.TFRecordReader()</span><br><span class="line">        key,value = reader.read(file_queue)</span><br><span class="line">        <span class="comment"># 读取tfrecords文件 需要解析example</span></span><br><span class="line">        feature = tf.parse_single_example(value,features=&#123;</span><br><span class="line">            <span class="string">&#x27;image&#x27;</span>:tf.FixedLenFeature([],tf.string),</span><br><span class="line">            <span class="string">&#x27;label&#x27;</span>:tf.FixedLenFeature([],tf.int64)</span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="comment"># 取出两个键值所对应的值</span></span><br><span class="line">        image = feature[<span class="string">&#x27;image&#x27;</span>]</span><br><span class="line">        label = feature[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image:&#x27;</span>,image)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;label:&#x27;</span>,label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码</span></span><br><span class="line">        image_decoded = tf.decode_raw(image,tf.uint8)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_decoded:&#x27;</span>,image_decoded)</span><br><span class="line">        <span class="comment"># print(image_decoded.shape)</span></span><br><span class="line">        <span class="comment"># 改变形状</span></span><br><span class="line">        image_reshaped = tf.reshape(image_decoded,shape = [<span class="number">64</span>,<span class="number">64</span>,self.channels])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_reshaped:&#x27;</span>,image_reshaped)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 批处理</span></span><br><span class="line">        image_batch,label_batch = tf.train.batch([image_reshaped,label],batch_size = <span class="number">100</span>,num_threads = <span class="number">1</span>,capacity = <span class="number">100</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;image_batch:&#x27;</span>,image_batch)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;label_batch:&#x27;</span>,label_batch)</span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            <span class="comment"># 开启线程</span></span><br><span class="line">            coord = tf.train.Coordinator()</span><br><span class="line">            threads = tf.train.start_queue_runners(sess=sess,coord=coord)</span><br><span class="line"></span><br><span class="line">            image_new,label_new,image_decoded_new,image_reshaped_new,image_batch_new,label_batch_new= sess.run([image,label,image_decoded,image_reshaped,image_batch,label_batch])</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_new:&#x27;</span>,image_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;label_new:&#x27;</span>,label_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_decoded_new:&#x27;</span>,image_decoded_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_reshaped_new:&#x27;</span>,image_reshaped_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;image_batch_new:&#x27;</span>,image_batch_new)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;label_batch_new:&#x27;</span>,label_batch_new)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 停止线程 回收线程</span></span><br><span class="line">            coord.request_stop()</span><br><span class="line">            coord.join(threads)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   <span class="comment"># # 返回指定路径下的文件和文件夹列表</span></span><br><span class="line">    <span class="comment"># file_name = os.listdir(&#x27;./cifar-10-batches-bin&#x27;)</span></span><br><span class="line">    <span class="comment"># print(&#x27;file_name:&#x27;,file_name)</span></span><br><span class="line">    <span class="comment"># # 路径 + 文件名  if file[-3:] == &#x27;bin&#x27;: 后缀bin的文件</span></span><br><span class="line">    <span class="comment"># file_list = [os.path.join(&#x27;./cifar-10-batches-bin&#x27;,file) for file in file_name if file[-3:] == &#x27;bin&#x27;]</span></span><br><span class="line">    <span class="comment"># print(&#x27;file_list:&#x27;,file_list)</span></span><br><span class="line"></span><br><span class="line">    CIFAR10 = CIFAR10()</span><br><span class="line">    <span class="comment"># label_batch,image_batch = CIFAR10.read_and_decode(file_list)  # CIFAR10二进制数据读取</span></span><br><span class="line">    <span class="comment"># CIFAR10.write_to_tfrecords(label_batch,image_batch)   # tfrecords文件存储</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># tfrecords文件读取</span></span><br><span class="line">    path = [<span class="string">&#x27;./cifar10.tfrecords&#x27;</span>]</span><br><span class="line">    CIFAR10.read_tfrecords(path)</span><br></pre></td></tr></table></figure><p><strong>参考资料</strong></p><blockquote><p><a href="https://blog.csdn.net/qq_44231797/article/details/125086565">(43条消息) 黑马程序员3天带你玩转Python深度学习TensorFlow框架学习笔记_wisdom_zhe的博客-CSDN博客</a></p><p><a href="https://www.cnblogs.com/coder-qi/p/10653419.html#%E7%8B%97%E5%9B%BE%E7%89%87%E8%AF%BB%E5%8F%96">【学习笔记】tensorflow图片读取 - coder-qi - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/coder-qi/p/10645332.html">【学习笔记】tensorflow文件读取 - coder-qi - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/coder-qi/p/10633464.html">【学习笔记】tensorflow队列和线程 - coder-qi - 博客园 (cnblogs.com)</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;数据读取处理&quot;&gt;&lt;a href=&quot;#数据读取处理&quot; class=&quot;headerlink&quot; title=&quot;数据读取处理&quot;&gt;&lt;/a&gt;&lt;strong&gt;数据读取处理&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&quot;1-文件读取&quot;&gt;&lt;a href=&quot;#1-文件读取&quot; class=</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>TensorFlow 笔记1</title>
    <link href="http://example.com/2023/03/28/TensorFlow%20%E7%AC%94%E8%AE%B01/"/>
    <id>http://example.com/2023/03/28/TensorFlow%20%E7%AC%94%E8%AE%B01/</id>
    <published>2023-03-28T15:29:38.000Z</published>
    <updated>2023-08-07T09:53:43.033Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Tensorflow的基本结构</strong></p><p>tensor（张量）:tensorflow的数据中央控制单元 每一个tensor都有一系列的初始值组成，这些初始值形成一个任意维数的数组（一般tensor的列即为它的维度）。flow（流动）。</p><p>Tensorflow程序通常有两个阶段：构建图阶段和执行图阶段。</p><p>构建图阶段：定义数据（张量[^tensor]）与操作(节点[^Op])，这些执行步骤被描述成一个图。</p><p>执行图阶段：使用会话（Session）执行构建好的图中的操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">node1 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line">node2 = tf.constant(<span class="number">4.0</span>)</span><br><span class="line">node3 = tf.add(node1,node2)</span><br><span class="line"><span class="built_in">print</span>(node1)<span class="comment"># Tensor(&quot;Const:0&quot;, shape=(), dtype=float32)</span></span><br><span class="line"><span class="built_in">print</span>(node2)<span class="comment"># Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32)</span></span><br><span class="line"><span class="built_in">print</span>(node3)<span class="comment"># Tensor(&quot;Add:0&quot;, shape=(), dtype=float32)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#执行一个图为默认的会话(Session(图为空))</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    node1_value=sess.run(node1)</span><br><span class="line">    node2_value=sess.run(node2)</span><br><span class="line">    node3_value=sess.run(node3)</span><br><span class="line">    <span class="built_in">print</span>(node1_value)<span class="comment"># 3.0</span></span><br><span class="line">    <span class="built_in">print</span>(node2_value)<span class="comment"># 4.0</span></span><br><span class="line">    <span class="built_in">print</span>(node3_value)<span class="comment"># 7.0</span></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure><p>tensorflow中的图 tf.graph()</p><ol><li>通过张量本身直接出graph</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">node=tf.constant(<span class="number">2.0</span>)</span><br><span class="line"><span class="comment"># 通过张量本身直接出graph</span></span><br><span class="line">default_graph=tf.get_default_graph()<span class="comment"># 获取当前的默认图结构</span></span><br><span class="line"><span class="built_in">print</span>(default_graph)</span><br><span class="line"><span class="comment"># &lt;tensorflow.python.framework.ops.Graph object at 0x000001EFCE019EF0&gt;</span></span><br><span class="line"></span><br><span class="line">sess=tf.Session()</span><br><span class="line">node_value=sess.run(node)</span><br><span class="line"><span class="built_in">print</span>(node.graph)</span><br><span class="line"><span class="built_in">print</span>(default_graph==node.graph)    <span class="comment"># True</span></span><br></pre></td></tr></table></figure><ol start="2"><li>通过声明一个默认的图，然后定义张量内容，在后面可以调用或保存</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">node1=tf.constant(<span class="number">4.0</span>)</span><br><span class="line">g=tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    node2=tf.constant(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">sess=tf.Session(graph=g)</span><br><span class="line">node_value=sess.run(node2)</span><br><span class="line"><span class="built_in">print</span>(g)</span><br><span class="line"><span class="built_in">print</span>(tf.get_default_graph())</span><br><span class="line"><span class="built_in">print</span>(node1.graph)</span><br><span class="line"><span class="comment"># node2:&lt;tensorflow.python.framework.ops.Graph object at 0x0000014501B59DA0&gt;</span></span><br><span class="line"><span class="comment"># &lt;tensorflow.python.framework.ops.Graph object at 0x0000014501B39F60&gt;</span></span><br><span class="line"><span class="comment"># &lt;tensorflow.python.framework.ops.Graph object at 0x0000014501B39F60&gt;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>通过多个声明，在后面可通过变量名分别调用（调用时Session()要写入对应的图的变量名）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g1=tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g1.as_default():</span><br><span class="line">    node1=tf.constant(<span class="number">2.0</span>)</span><br><span class="line">g2=tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g2.as_default():</span><br><span class="line">    node2=tf.constant(<span class="number">5.0</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=g1) <span class="keyword">as</span> sess1:</span><br><span class="line">    node1_value=sess1.run(node1)</span><br><span class="line">    <span class="built_in">print</span>(g1)</span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=g2) <span class="keyword">as</span> sess2:</span><br><span class="line">    node2_value=sess2.run(node2)</span><br><span class="line">    <span class="built_in">print</span>(g2)    </span><br></pre></td></tr></table></figure><p><strong>TensorFlow的对graph的常用操作</strong></p><ol><li>保存图(pb文件)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g1=tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g1.as_default():</span><br><span class="line">    node1=tf.constant(<span class="number">2.0</span>,name=<span class="string">&#x27;node1&#x27;</span>)</span><br><span class="line">g2=tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g2.as_default():</span><br><span class="line">    node2=tf.constant(<span class="number">3.0</span>,name=<span class="string">&#x27;node2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=g1) <span class="keyword">as</span> sess1:</span><br><span class="line">    <span class="built_in">print</span>(sess1.run(node1))</span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=g2) <span class="keyword">as</span> sess2:</span><br><span class="line">    <span class="built_in">print</span>(sess2.run(node2))</span><br><span class="line"><span class="comment"># g1的图定义 包含pb的path，pb文件名，是否为文本 默认False</span></span><br><span class="line">tf.train.write_graph(g1.as_graph_def(),<span class="string">&#x27;.&#x27;</span>,<span class="string">&#x27;graph.pb&#x27;</span>,<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​<code>tf.reset_default_graph</code>：对图进行重置。每使用一次，重置的新图，分配不同的地址。</p><p>​<code>g1.as_graph_def()</code>：将图进行序列化。</p><p>​<code>tf.train.write_graph()</code>：将序列化的图保存。一般不适用这个api，这样保存的模型，只能用于测试。（一般保存为 .ckpt 文件，用于继续训练或测试，直到效果ok再进行保存pb文件 ）</p><ol start="2"><li>调用pb文件的图</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> gfile</span><br><span class="line"></span><br><span class="line"><span class="comment"># load graph</span></span><br><span class="line"><span class="keyword">with</span> gfile.FastGFile(<span class="string">&#x27;./graph.pb&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    graph_def=tf.GraphDef() <span class="comment"># 创建一个序列化的空图</span></span><br><span class="line">    graph_def.ParseFromString(f.read()) <span class="comment"># 把pb文件导入到创建的序列化空图中</span></span><br><span class="line">    tf.import_graph_def(graph_def,name=<span class="string">&#x27;&#x27;</span>)  <span class="comment"># 将序列化图导入到当前图中</span></span><br><span class="line"></span><br><span class="line">sess=tf.Session()</span><br><span class="line">node1_tensor=sess.graph.get_tensor_by_name(<span class="string">&#x27;node1:0&#x27;</span>)</span><br><span class="line"><span class="comment"># 从图中获取到命名为&quot;node1:0&quot;的tensor，该tensor为&quot;node1&quot;节点的第0个输出</span></span><br><span class="line">node1=sess.run(node1_tensor)</span><br><span class="line"><span class="built_in">print</span>(node1)</span><br></pre></td></tr></table></figure><p><strong>序列化和反序列化</strong></p><p>序列化：把对象转化为可传输的字节序列过程称为序列化。</p><p>反序列化：把字节序列还原为对象的过程称为反序列化。</p><p>序列化最终的目的是为了对象可以<strong>跨平台存储，和进行网络传输</strong>。而我们进行跨平台存储和网络传输的方式就是IO，而我们的IO支持的数据格式就是字节数组。</p><p>因为我们单方面的只把对象转成字节数组还不行，因为没有规则的字节数组我们是没办法把对象的本来面目还原回来的，所以我们必须在把对象转成字节数组的时候就制定一种规则（<strong>序列化</strong>），那么我们从IO流里面读出数据的时候再以这种规则把对象还原回来（<strong>反序列化</strong>）。</p><p><strong>一般来讲，TensorFlow 有三种文件格式：</strong></p><p><strong>checkpoint</strong>：一种独有的文件格式，包含四个文件。保存了计算图和权重，无法直接打开阅读。多用于训练时。<br>​<strong>pb</strong>：protobuf 格式的二进制文件，可以只保存计算图（很小），也同时保存了权重和计算图（很大），无法直接打开阅读。<br>包含权重的文件中所有的 variable 都已经变成了 tf.constant 和 graph 一起 frozen 到一个文件。<br>​<strong>pbtxt</strong>：pb 文件的可读文本，如果同时保存权重，文件会很大，一般用的比较少，可用于调试查看网络结构。</p><p><strong>会话</strong></p><ul><li><p>tf.Session() :用于完整的程序当中，会话掌握着资源，用完需要回收，因此一般使用with上下文管理器。</p><p>如果在创建Session时没有指定Graph，则该Session会加载默认Graph。如果创建了多个Graph，则需要创建不同的Session来加载每个Graph，而每个Graph则可以加载在多个Session中进行计算。</p><p><code>tf.eval()</code>只适用于tensor，一次只能获得<strong>一个张量</strong>的值；而<code>session.run()</code>不仅适用于tensor，还可用于没有输出的op,可以在同一步骤中获取许多张量的值；对于tensor，调用session.run()与tensor.eval()是等价的。</p><p>初始化会话以下三个参数：</p><ul><li>target</li><li>graph</li><li>config</li></ul></li><li><p>tf.interactiveSession:用于交互式上下文的TensorFlow。</p></li></ul><p><strong>Fetch and Feed</strong></p><ul><li>Fetch操作是指在会话当中，可以在sess.run()时同时运行一个或多个op；将多个op组成列表，传入run中可以得到多个op的输出结果。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">node1 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line">node2 = tf.constant(<span class="number">4.0</span>)</span><br><span class="line">add = tf.add(node1, node2)</span><br><span class="line">mul = tf.multiply(node1, node2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    node1_value = sess.run(node1)</span><br><span class="line">    node2_value = sess.run(node2)</span><br><span class="line">    value = sess.run([add,mul])</span><br><span class="line">    <span class="built_in">print</span>(value)  <span class="comment"># [7.0, 12.0]</span></span><br></pre></td></tr></table></figure><ul><li>Feed操作需要在开始时通过占位符(placeholder)来声明数据。</li></ul><p>为什么需要feed操作：当我们构建一个模型时，常常需要我们在运行时候输入一系列数据，通过占位符可以提前声明这些数据；在train数据时,可以在一个graph上同时使用一个op，每一次写入的时候都会替换上一次的值，减少了graph的开销。</p><p>由定义<code>def placeholder(dtype,shape=None,name=None);</code>可知声明时需要给定类型dtype。</p><p>占位符不需要初始化。可以把feed_dict看作它特有的一种初始化方式。shape默认下feed_dict的数据的维度可任意。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a=tf.placeholder(tf.float32)</span><br><span class="line">b=tf.placeholder(tf.float32)</span><br><span class="line">c=tf.add(a,b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result=sess.run(c,feed_dict=&#123;a:<span class="number">1</span>,b:<span class="number">2</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><p><strong>张量(Tensors)</strong></p><p>TensorFlow 是一个定义和运行张量计算的框架。张量是各种维度的向量和矩阵的统称。在内部，TensorFlow 用基本数据类型的多维数组来表示张量。</p><p>在写 TensorFlow 程序的时候，主要操作和传递的对象就是 tf.Tensor，即张量。</p><p>tf.Tensor对象的数据类型和张量的类型不是同一个概念。tf.Tensor对象的数据类型一般为float32，int32等；张量的类型一般为<code>tf.constant``,tf.Variabale</code>,<code>tf.placeholder</code>,除了<code>tf.Variable</code>以外，张量的值是不可变的，也就是说张量在单次执行的上下文中值是唯一的。但是，两次对同一个张量求值可能返回不同的值，比如，张量的值可能是从磁盘读取的数据，或者是一个随机数，那么每次产生的结果可能是不一样的。</p><ul><li><p><strong>四种常见的Tensor</strong></p></li><li><ul><li><strong>1. 常量Tensor</strong>：值不能改变，常用<code>tf.constant(value,dtype=None,shape=None,name=&#39;Const&#39;,verify_shape=False)</code>创建,其中value值必须给定，<code>verify_shape</code>默认该常量的形状不可改。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.zeros(shape,dtype=tf.float32,name=None) 产生全0的张量</span></span><br><span class="line">tensor1=tf.zeros(shape=[<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># 创建一个和输入图像（tensor1）一样维度元素都为 0 的张量</span></span><br><span class="line">tensor1_1=tf.zeros_like(tensor1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.ones(shape,dtype=tf.float32,name=None) 产生全1的张量</span></span><br><span class="line">tensor2=tf.ones(shape=[<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># 创建一个和输入图像（tensor2）一样维度元素都为 1 的张量</span></span><br><span class="line">tensor2_1=tf.ones_like(tensor1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(sess.run(tensor1))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(tensor2))</span><br></pre></td></tr></table></figure><p>常量Tensor无需初始化，但仍需在会话<code>tf.Session()</code>中获取数据，即数据只会在会话中流动。</p><ul><li><p><strong>2. 变量Tensor</strong>:值可以改变，<strong>可训练</strong>。在神经网络中，<strong>变量</strong>一般可作为储存权重和其他信息的矩阵，而<strong>常量</strong>可作为储存超参数或其他结构信息的变量，<strong>变量必须初始化</strong>。</p><ul><li><p><code>tf.Variable(initial_value, dtype=None, name=None, trainable=True, collections=None,validate_shape=True)</code></p><p>全局变量初始化：<code>tf.global_variables_initializer()</code></p><p>将一个变量的值赋值给另一个变量：<code>initialized_value()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">weight1 = tf.Variable(tf.ones(shape=[<span class="number">3</span>],name=<span class="string">&#x27;weight1&#x27;</span>))</span><br><span class="line"><span class="comment"># 用已经初始化的weight1作为weight2的值</span></span><br><span class="line">weight2 = tf.Variable(weight1.initialized_value(),name=<span class="string">&#x27;weight2&#x27;</span>)</span><br><span class="line">weight_twice = tf.Variable(weight1.initialized_value() * <span class="number">2</span>,name=<span class="string">&#x27;weight_twice&#x27;</span>)</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="built_in">print</span>(weight1.<span class="built_in">eval</span>(),weight2.<span class="built_in">eval</span>(),weight_twice.<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure><p>运行变量的初始化函数：<code>variable.initializer()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">weight = tf.Variable(tf.ones(shape=[<span class="number">3</span>]),name=<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># weight.initializer.run()  两者相同</span></span><br><span class="line">    sess.run(weight.initializer) <span class="comment"># 仅仅初始化weight本身</span></span><br><span class="line">    <span class="built_in">print</span>(weight.<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure></li><li><p><code>tf.get_variable( name, shape=None,dtype=None, initializer=None,  trainable=True,  regularizer=None,collections=None, caching_device=None, partitioner=None, validate_shape=True,  use_resource=None,  custom_getter=None)</code>，这里的initializer初始化之后并没有实际的数据，当开启session时，才将相应的初始化数据传给tensor。</p><ol><li>初始化initializer常量</li></ol><p>通过<code>tf.constant</code>初始化variable不需要给定shape，其dtype由constant的值决定。</p><p>通过<code>tf.constant_initializer</code>初始化variable需要给定shape ，其dtype为float32_ref</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># init_const = tf.constant([[1,2],[3,4]])</span></span><br><span class="line"><span class="comment"># x = tf.get_variable(initializer=init_const,name=&#x27;x&#x27;)</span></span><br><span class="line"><span class="comment"># [[1 2]</span></span><br><span class="line"><span class="comment">#  [3 4]]</span></span><br><span class="line"><span class="comment"># &lt;tf.Variable &#x27;x:0&#x27; shape=(2, 2) dtype=int32_ref&gt;</span></span><br><span class="line"></span><br><span class="line">init_const = tf.constant_initializer([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">x = tf.get_variable(initializer=init_const,name=<span class="string">&#x27;x&#x27;</span>,shape=[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line"><span class="comment"># [[1. 2.]</span></span><br><span class="line"><span class="comment">#  [3. 4.]]</span></span><br><span class="line"><span class="comment"># &lt;tf.Variable &#x27;x:0&#x27; shape=(2, 2) dtype=float32_ref&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="built_in">print</span>(x.<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure><ol start="2"><li><ul><li><p>初始化initializer为 标准正态分布：<code>tf.random_normal_initializer()</code></p></li><li><p>初始化initializer为 截断正态分布：<code>tf.truncated_normal_initializer()</code>根据<strong>正态分布的3σ原则</strong>，将小于μ-3σ和大于μ+3σ的值截断剩下 <code>μ-3σ&lt;x&lt;μ+3σ</code> 之间的值。</p></li><li><p>初始化initializer为 均匀分布：    <code>tf.random_uniform_initializer() </code></p></li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">init_random = tf.random_normal_initializer(mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>)</span><br><span class="line">y1 = tf.get_variable(initializer=init_random, name=<span class="string">&#x27;y&#x27;</span>, shape=[<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">init_truncated = tf.truncated_normal_initializer(mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>)</span><br><span class="line">y2 = tf.get_variable(initializer=init_truncated, name=<span class="string">&#x27;y2&#x27;</span>, shape=[<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">init_uniform = tf.random_uniform_initializer(minval=<span class="number">0</span>,maxval=<span class="number">10</span>)</span><br><span class="line">y3 = tf.get_variable(initializer=init_uniform,name=<span class="string">&#x27;y3&#x27;</span>,shape=[<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="built_in">print</span>(y1.<span class="built_in">eval</span>())</span><br><span class="line">    <span class="built_in">print</span>(y2.<span class="built_in">eval</span>())</span><br><span class="line">    <span class="built_in">print</span>(y3.<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure></li><li><p><code>tf.Variable()</code>与<code>tf.get_variable()</code>的区别</p><ol><li><strong>变量共享</strong>：</li></ol><p>使用tf.Variable()时，如果系统检测到命名相同，系统会<strong>自动加后缀</strong>，<strong>不支持变量共享</strong>。<br>使用tf.get_variable()，如果系统检测到命名相同，且参数<strong>reuse&#x3D;True</strong>，那么直接共享之前的变量值，<strong>支持变量共享</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">with tf.variable_scope(&#x27;scope1&#x27;):</span><br><span class="line">    w1 = tf.Variable(1, name=&#x27;w1&#x27;)</span><br><span class="line">    w2 = tf.get_variable(initializer=2.0, name=&#x27;w2&#x27;)</span><br><span class="line">    </span><br><span class="line">with tf.variable_scope(&#x27;scope1&#x27;, reuse=True):</span><br><span class="line">    w1_p = tf.Variable(5, name=&#x27;w1&#x27;)</span><br><span class="line">    w2_p = tf.get_variable(initializer=3.0, name=&#x27;w2&#x27;)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    print(w1.eval())        # 1</span><br><span class="line">    print(w2.eval())        # 2.0</span><br><span class="line">    print(w1_p.eval())      # 5   变量共享不了</span><br><span class="line">    print(w2_p.eval())      # 2.0 变量共享了W1</span><br><span class="line"></span><br><span class="line">print(w1.name, w1_p.name)# scope1/w1:0 scope1_1/w1:0</span><br><span class="line">print(w2.name, w2_p.name)# scope1/w2:0 scope1/w2:0</span><br></pre></td></tr></table></figure><ol start="2"><li><code>tf.variable_scope()</code>可以对所有op加上前缀，指明作用域空间。<code>tf.name_scope()</code><strong>不能</strong>给<code>tf.get_variable()</code>变量指明作用域空间。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.name_scope()</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;scope1&#x27;</span>):</span><br><span class="line">    w0 = tf.constant(<span class="number">1</span>,name=<span class="string">&#x27;w0&#x27;</span>)</span><br><span class="line">    w1 = tf.Variable(<span class="number">1</span>,name=<span class="string">&#x27;w1&#x27;</span>)</span><br><span class="line">    w2 = tf.get_variable(initializer=<span class="number">2.0</span>,name=<span class="string">&#x27;w2&#x27;</span>)</span><br><span class="line"><span class="comment"># tf.variable_scope()</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;scope2&#x27;</span>):</span><br><span class="line">    w0_p = tf.constant(<span class="number">2</span>,name=<span class="string">&#x27;w0_p&#x27;</span>)</span><br><span class="line">    w1_p = tf.Variable(<span class="number">5</span>,name=<span class="string">&#x27;w1_p&#x27;</span>)</span><br><span class="line">    w2_p = tf.get_variable(initializer=<span class="number">3.0</span>,name=<span class="string">&#x27;w2_p&#x27;</span>)</span><br><span class="line"><span class="comment"># w2没有确定作用域空间</span></span><br><span class="line"><span class="built_in">print</span>(w0.name, w1.name, w2.name)<span class="comment"># scope1/w0:0 scope1/w1:0 w2:0</span></span><br><span class="line"><span class="built_in">print</span>(w0_p.name,w1_p.name,w2_p.name)<span class="comment"># scope2/w0_p:0 scope2/w1_p:0 scope2/w2_p:0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>3. 占位符placeholder</strong></p></li><li><p><strong>4. 稀疏张量SparseTensor</strong>:定义时只需要定义非0的数，其他数会自动填充。<code>def tf.SparseTensor(values,indices,dense_shape)</code></p><ul><li>indices：非零值所对应的索引。</li><li>values：对应索引位置的值。</li><li>dense_shape：稀疏张量所对应的稠密张量的形状。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 稀疏张量 只需要给对应位置非0的值即可</span></span><br><span class="line">sparse_tensor=tf.SparseTensor(indices=[[<span class="number">0</span>,<span class="number">0</span>],values=[<span class="number">1</span>,<span class="number">5</span>],[<span class="number">1</span>,<span class="number">2</span>]],dense_shape=[<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># 稠密张量 将稀疏张量转化为稠密张量</span></span><br><span class="line">dense_tensor=tf.sparse_tensor_to_dense(sparse_tensor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(sess.run(sparse_tensor))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(dense_tensor))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出如下:</span></span><br><span class="line"><span class="string">SparseTensorValue(indices=array([[0, 0],</span></span><br><span class="line"><span class="string">       [1, 2]], dtype=int64), values=array([1, 5]), dense_shape=array([3, 4], dtype=int64))</span></span><br><span class="line"><span class="string">[[1 0 0 0]</span></span><br><span class="line"><span class="string"> [0 0 5 0]</span></span><br><span class="line"><span class="string"> [0 0 0 0]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>张量的秩</strong></p></li></ul><p><code>tf.Tensor</code> 对象的秩就是它维度的数量。秩的也可以叫做阶数、度数或者是 n 维。注意：Tensorflow 里的秩和数学中矩阵的秩是不一样的。</p><table><thead><tr><th align="center">秩</th><th align="center">数学实体</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">标量</td></tr><tr><td align="center">1</td><td align="center">向量</td></tr><tr><td align="center">2</td><td align="center">矩阵（二维矩阵）</td></tr><tr><td align="center">3</td><td align="center">3维张量(由数构成的方体)</td></tr><tr><td align="center">4</td><td align="center">4维张量（常用于图像处理）</td></tr><tr><td align="center">n</td><td align="center">n维张量</td></tr></tbody></table><ul><li><strong><code>tf.rank</code>获取张量的秩</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tensor0 = tf.constant(<span class="number">1</span>)  <span class="comment"># 0阶</span></span><br><span class="line">tensor1 = tf.constant([<span class="number">2</span>, <span class="number">3</span>])  <span class="comment"># 1阶</span></span><br><span class="line">tensor2 = tf.constant([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])  <span class="comment"># 2阶</span></span><br><span class="line"><span class="comment"># 图像处理常用</span></span><br><span class="line">image = tf.zeros([<span class="number">10</span>, <span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>])  <span class="comment"># 4阶</span></span><br><span class="line"><span class="comment"># 各个维度分别代表一个样本批次的大小、图像的宽度、图像的高度以及颜色通道数。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.rank(tensor0)))  <span class="comment"># 0</span></span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.rank(tensor1)))  <span class="comment"># 1</span></span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.rank(tensor2)))  <span class="comment"># 2</span></span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.rank(image)))    <span class="comment"># 4</span></span><br></pre></td></tr></table></figure><ul><li><strong><code>tf.reshape</code>改变tensor对象的形状</strong></li></ul><p>变形前后的张量元素个数必须相同，如果不同，就会产生错误。</p><p><code>Tensor.eval</code>用来求取张量的值。只能在启用了一个默认的会话才能正常使用，当Tensor的信息是不确定的，如使用<code>placeholder</code>的张量在没有给<code>placeholder</code>提供值之前是无法进行评估的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">matrixA=tf.ones([<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">matrixB=tf.reshape(matrixA,[<span class="number">4</span>,<span class="number">15</span>])</span><br><span class="line">matrixC=tf.reshape(matrixB,[<span class="number">3</span>,-<span class="number">1</span>])</span><br><span class="line">matrixD=tf.reshape(matrixB,[<span class="number">4</span>,<span class="number">3</span>,-<span class="number">1</span>])</span><br><span class="line"><span class="comment"># -1 会自动计算这一维度的大小</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(matrixA.<span class="built_in">eval</span>())</span><br><span class="line">    <span class="built_in">print</span>(matrixA)<span class="comment"># Tensor(&quot;ones:0&quot;, shape=(3, 4, 5), dtype=float32)</span></span><br><span class="line">    <span class="built_in">print</span>(matrixB)<span class="comment"># Tensor(&quot;Reshape:0&quot;, shape=(4, 15), dtype=float32)</span></span><br><span class="line">    <span class="built_in">print</span>(matrixC)<span class="comment"># Tensor(&quot;Reshape_1:0&quot;, shape=(3, 20), dtype=float32)</span></span><br><span class="line">    <span class="built_in">print</span>(matrixD)<span class="comment"># Tensor(&quot;Reshape_2:0&quot;, shape=(4, 3, 5), dtype=float32)</span></span><br><span class="line">    <span class="built_in">print</span>(sess.run(matrixA))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(matrixB))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(matrixC))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(matrixD))</span><br></pre></td></tr></table></figure><ul><li><strong><code>tf.slice()</code>分割张量。</strong></li></ul><p><code>tf.slice()</code>从张量中提取想要的切片，由begin指定位置开始的张量提取尺寸为size的切片。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">slice</span>(<span class="params">input_,begin,size,name=<span class="literal">None</span></span>)</span><br><span class="line"></span><br><span class="line">input_:类型为一个tensor，表示的是输入的tensor，也就是被切的那个.</span><br><span class="line">begin:是一个int32或int64类型的tensor，表示的是每一个维度的起始位置.</span><br><span class="line">size:是一个int32或int64类型的tensor，表示的是每个维度要拿的元素数.</span><br><span class="line">name:操作的名称，可写可不写.</span><br></pre></td></tr></table></figure><p>通过切片实现简单的ROI（Region of interest）提取</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"></span><br><span class="line">src = cv.imread(<span class="string">&quot;F:/Software/opencv-python-image/image/camera.jpg&quot;</span>)</span><br><span class="line">cv.imshow(<span class="string">&quot;input&quot;</span>, src)</span><br><span class="line">image = tf.placeholder(shape=[<span class="literal">None</span>, <span class="literal">None</span>, <span class="number">3</span>], dtype=tf.uint8, name=<span class="string">&quot;image&quot;</span>)</span><br><span class="line">roi_image = tf.<span class="built_in">slice</span>(image, [<span class="number">35</span>,<span class="number">20</span>, <span class="number">0</span>], [<span class="number">180</span>, <span class="number">180</span>, -<span class="number">1</span>]) <span class="comment"># -1自动计算总通道数 若改为1则为灰度图像</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess: </span><br><span class="line">    <span class="built_in">slice</span> = sess.run(roi_image, feed_dict=&#123;image:src&#125;)</span><br><span class="line">    <span class="built_in">print</span>(roi_image)</span><br><span class="line">    cv.imshow(<span class="string">&quot;roi&quot;</span>, <span class="built_in">slice</span>)</span><br><span class="line">    cv.waitKey(<span class="number">0</span>)</span><br><span class="line">    cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><strong>参考资料</strong></p><blockquote><p>[1] <a href="https://zhuanlan.zhihu.com/p/45476929">TensorFlow 中的几个关键概念：Tensor，Operation，Graph，Session - 知乎 (zhihu.com)</a></p><p>[2] <a href="https://zhuanlan.zhihu.com/p/40462507">序列化理解起来很简单 - 知乎 (zhihu.com)</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Tensorflow的基本结构&lt;/strong&gt;	&lt;/p&gt;
&lt;p&gt;tensor（张量）:tensorflow的数据中央控制单元 每一个tensor都有一系列的初始值组成，这些初始值形成一个任意维数的数组（一般tensor的列即为它的维度）。flow（流动）。</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2023/03/25/hello-world/"/>
    <id>http://example.com/2023/03/25/hello-world/</id>
    <published>2023-03-25T12:30:00.000Z</published>
    <updated>2023-08-04T13:51:27.248Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
